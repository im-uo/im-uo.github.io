@article{katirai2024socialissues,
 abstract = {The race to develop image generation models is intensifying, with a rapid increase in the number of text-to-image models available. This is coupled with growing public awareness of these technologies. Though other generative AI models---notably, large language modelsâ€”have received recent critical attention for the social and other non-technical issues they raise, there has been relatively little comparable examination of image generation models. This paper reports on a novel, comprehensive categorization of the social issues associated with image generation models. At the intersection of machine learning and the social sciences, we report the results of a survey of the literature, identifying seven issue clusters arising from image generation models: data issues, intellectual property, bias, privacy, and the impacts on the informational, cultural, and natural environments. We situate these social issues in the model life cycle, to aid in considering where potential issues arise, and mitigation may be needed. We then compare these issue clusters with what has been reported for large language models. Ultimately, we argue that the risks posed by image generation models are comparable in severity to the risks posed by large language models, and that the social impact of image generation models must be urgently considered, even as their development and deployment are pushed forward.},
 author = {Amelia Katirai and Noa Garcia and Kazuki Ide and Yuta Nakashima and Atsuo Kishimoto},
 doi = {https://doi.org/10.1007/s43681-024-00517-3},
 journal = {AI and Ethics},
 month = {7},
 pages = {pp.~1--18},
 title = {Situating the social issues of image generation models in the model life cycle: a sociotechnical approach},
 url = {https://link.springer.com/article/10.1007/s43681-024-00517-3},
 year = {2024}
}
