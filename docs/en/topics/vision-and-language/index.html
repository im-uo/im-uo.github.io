<!doctype html><html lang=en-us dir=ltr data-wc-theme-default=system><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 0.3.1"><meta name=author content="Department of Intelligent Media"><meta name=description content="Ë¶ñË¶ö„Å®Ëá™ÁÑ∂Ë®ÄË™û„ÇíËûçÂêà„Åó„Å¶„Çà„ÇäÊ∑±„ÅÑÊÑèÂë≥ÁêÜËß£„ÇíÁõÆÊåá„Åô"><link rel=alternate hreflang=ja href=https://im.sanken.osaka-u.ac.jp/ja/topics/vision-and-language/><link rel=alternate hreflang=en-us href=https://im.sanken.osaka-u.ac.jp/en/topics/vision-and-language/><link rel=stylesheet href=/css/themes/emerald.min.css><link href=/dist/wc.min.css rel=stylesheet><script>window.hbb={defaultTheme:document.documentElement.dataset.wcThemeDefault,setDarkTheme:()=>{document.documentElement.classList.add("dark"),document.documentElement.style.colorScheme="dark"},setLightTheme:()=>{document.documentElement.classList.remove("dark"),document.documentElement.style.colorScheme="light"}},console.debug(`Default Hugo Blox Builder theme is ${window.hbb.defaultTheme}`),"wc-color-theme"in localStorage?localStorage.getItem("wc-color-theme")==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme():(window.hbb.defaultTheme==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme(),window.hbb.defaultTheme==="system"&&(window.matchMedia("(prefers-color-scheme: dark)").matches?window.hbb.setDarkTheme():window.hbb.setLightTheme()))</script><script>document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll("li input[type='checkbox'][disabled]");e.forEach(e=>{e.parentElement.parentElement.classList.add("task-list")});const t=document.querySelectorAll(".task-list li");t.forEach(e=>{let t=Array.from(e.childNodes).filter(e=>e.nodeType===3&&e.textContent.trim().length>1);if(t.length>0){const n=document.createElement("label");t[0].after(n),n.appendChild(e.querySelector("input[type='checkbox']")),n.appendChild(t[0])}})})</script><link rel=icon type=image/png href=/media/icon_hu_5cac115d14ed3d49.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu_e7f327b39c12e7ca.png><link rel=canonical href=https://im.sanken.osaka-u.ac.jp/en/topics/vision-and-language/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@GetResearchDev"><meta property="twitter:creator" content="@GetResearchDev"><meta property="og:site_name" content="Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂÆ§"><meta property="og:url" content="https://im.sanken.osaka-u.ac.jp/en/topics/vision-and-language/"><meta property="og:title" content="Vision and Language | Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂÆ§"><meta property="og:description" content="Ë¶ñË¶ö„Å®Ëá™ÁÑ∂Ë®ÄË™û„ÇíËûçÂêà„Åó„Å¶„Çà„ÇäÊ∑±„ÅÑÊÑèÂë≥ÁêÜËß£„ÇíÁõÆÊåá„Åô"><meta property="og:image" content="https://im.sanken.osaka-u.ac.jp/en/topics/vision-and-language/featured.jpg"><meta property="twitter:image" content="https://im.sanken.osaka-u.ac.jp/en/topics/vision-and-language/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-10-24T00:00:00+00:00"><meta property="article:modified_time" content="2023-10-24T00:00:00+00:00"><title>Vision and Language | Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂÆ§</title><style>@font-face{font-family:inter var;font-style:normal;font-weight:100 900;font-display:swap;src:url(/dist/font/Inter.var.woff2)format(woff2)}</style><link type=text/css rel=stylesheet href=/dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css integrity="sha256-vnZutBkxehTsdp0hbpd5v+jzc3yA54D0ug2vtXpBpII="><script src=/dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script><script>window.hbb.pagefind={baseUrl:"/"}</script><style>html.dark{--pagefind-ui-primary:#eeeeee;--pagefind-ui-text:#eeeeee;--pagefind-ui-background:#152028;--pagefind-ui-border:#152028;--pagefind-ui-tag:#152028}</style><script>window.addEventListener("DOMContentLoaded",e=>{new PagefindUI({element:"#search",showSubResults:!0,baseUrl:window.hbb.pagefind.baseUrl,bundlePath:window.hbb.pagefind.baseUrl+"pagefind/"})}),document.addEventListener("DOMContentLoaded",()=>{let e=document.getElementById("search"),t=document.getElementById("search_toggle");t&&t.addEventListener("click",()=>{if(e.classList.toggle("hidden"),e.querySelector("input").value="",e.querySelector("input").focus(),!e.classList.contains("hidden")){let t=document.querySelector(".pagefind-ui__search-clear");t&&!t.hasAttribute("listenerOnClick")&&(t.setAttribute("listenerOnClick","true"),t.addEventListener("click",()=>{e.classList.toggle("hidden")}))}})})</script><script defer src=/js/hugo-blox-en.min.8c8ea06bd0420f5067e52fa727b9f92303757322ba4431774153d59a9735eadb.js integrity="sha256-jI6ga9BCD1Bn5S+nJ7n5IwN1cyK6RDF3QVPVmpc16ts="></script><script async defer src=https://buttons.github.io/buttons.js></script></head><body class="dark:bg-hb-dark dark:text-white page-wrapper" id=top><div id=page-bg></div><div class="page-header sticky top-0 z-30"><header id=site-header class=header><nav class="navbar px-3 flex justify-left"><div class="order-0 h-100"><a class=navbar-brand href=/en/ title=Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂÆ§><img fetchpriority=high decoding=async width=40 height=36 src=/media/logo_hu_b09ae69da4110657.webp alt=Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂÆ§>
mimlab</a></div><input id=nav-toggle type=checkbox class=hidden>
<label for=nav-toggle class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1"><svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20"><title>Open Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z"/></svg><svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20"><title>Close Menu</title><polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)"/></svg></label><ul id=nav-menu class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-left"><li class=nav-item><a class=nav-link href=/en/>top</a></li><li class=nav-item><a class=nav-link href=/en/#people>people</a></li><li class=nav-item><a class=nav-link href=/en/publication>publications</a></li><li class=nav-item><a class=nav-link href=/en/topics>research topics</a></li><li class=nav-item><a class=nav-link href=/en/#contact>contact</a></li></ul><div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0"><button aria-label=search class="text-black hover:text-primary inline-block px-3 text-xl dark:text-white" id=search_toggle><svg height="16" width="16" viewBox="0 0 512 512" fill="currentcolor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8.0 45.3s-32.8 12.5-45.3.0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9.0 208S93.1.0 208 0 416 93.1 416 208zM208 352a144 144 0 100-288 144 144 0 100 288z"/></svg></button><div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
[&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white"><button class="theme-toggle mt-1" accesskey=t title=appearance><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:hidden"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:block [&:not(dark)]:hidden"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div><div class="pl-1 mr-5 text-gray-600 hover:text-gray-800 dark:text-gray-400 dark:hover:text-gray-200
[&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white"><div class="flex justify-items-start"><button title=Languages data-state=closed data-hb-language-chooser class="grow h-7 rounded-md px-2 text-left text-xs font-medium text-gray-600 transition-colors dark:text-gray-400 hover:bg-gray-100 hover:text-gray-900 dark:hover:bg-primary-100/5 dark:hover:text-gray-50" type=button aria-label=Languages><div class="flex items-center gap-2 capitalize"><svg height="18" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 21a9.004 9.004.0 008.716-6.747M12 21a9.004 9.004.0 01-8.716-6.747M12 21c2.485.0 4.5-4.03 4.5-9S14.485 3 12 3m0 18c-2.485.0-4.5-4.03-4.5-9S9.515 3 12 3m0 0a8.997 8.997.0 017.843 4.582M12 3A8.997 8.997.0 004.157 7.582m15.686.0A11.953 11.953.0 0112 10.5c-2.998.0-5.74-1.1-7.843-2.918m15.686.0A8.959 8.959.0 0121 12c0 .778-.099 1.533-.284 2.253m0 0A17.919 17.919.0 0112 16.5a17.92 17.92.0 01-8.716-2.247m0 0A9.015 9.015.0 013 12c0-1.605.42-3.113 1.157-4.418"/></svg><span>English</span></div></button><ul class="fixed m-0 min-w-[100px] hidden z-20 max-h-64 overflow-auto rounded-md ring-1 ring-black/5 bg-white py-1 text-sm shadow-lg dark:ring-white/20 dark:bg-neutral-800" style="inset:auto auto 0 0"><li class="flex flex-col"><a href=https://im.sanken.osaka-u.ac.jp/ja/topics/vision-and-language/ class="relative cursor-pointer text-gray-800 dark:text-gray-100 hover:bg-primary-50 hover:text-primary-600 hover:dark:bg-primary-500/10 hover:dark:text-primary-200 whitespace-nowrap py-1.5 transition-colors ltr:pl-3 ltr:pr-9 rtl:pr-3 rtl:pl-9">Êó•Êú¨Ë™û</a></li></ul></div></div></div></nav></header><div id=search class="hidden p-3"></div></div><div class="page-body my-10"><div class="mx-auto flex max-w-screen-xl"><div class="hb-sidebar-mobile-menu fixed inset-0 z-10 bg-white dark:bg-black/80 hidden"></div><aside class="hb-sidebar-container max-lg:[transform:translate3d(0,-100%,0)] lg:sticky"><div class="px-4 pt-4 lg:hidden"></div><div class="hb-scrollbar lg:h-[calc(100vh-var(--navbar-height))]"><ul class="flex flex-col gap-1 lg:hidden"><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/post/>Blog
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/post/renewal/>üîÑ The Department of Intelligent Media</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/post/recruit/>üßë‚Äçüéì For Prospective Students</a></li></ul></div></li><li class=open><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/topics/>Research Topics
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/topics/ethical-ai/>AI„ÅÆ„Éê„Ç§„Ç¢„Çπ„Å®„Åù„ÅÆ‰ΩéÊ∏õ</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/topics/agent-by-llms/>Â§ßË¶èÊ®°„É¢„Éá„É´„ÅÆÂøúÁî®</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/topics/explainable-ai/>Ë™¨ÊòéÂèØËÉΩ„Å™AI</a></li><li class="flex flex-col open"><a class="hb-sidebar-custom-link
sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900" href=/en/topics/vision-and-language/>Vision and Language</a><ul class=hb-sidebar-mobile-toc><li><a href=#explain-me-the-painting-%e7%b5%b5%e7%94%bb%e3%81%ae%e8%aa%ac%e6%98%8e%e6%96%87%e7%94%9f%e6%88%90 class=hb-docs-link>Explain Me the Painting: ÁµµÁîª„ÅÆË™¨ÊòéÊñáÁîüÊàê</a></li><li><a href=#%e9%83%a8%e5%88%86%e6%98%a0%e5%83%8f%e6%a4%9c%e7%b4%a2%e3%81%ae%e6%80%a7%e8%83%bd%e8%a9%95%e4%be%a1%e3%81%ab%e3%81%8a%e3%81%91%e3%82%8b%e8%a1%a8%e5%b1%a4%e7%9a%84%e7%9b%b8%e9%96%a2%e3%81%ae%e5%95%8f%e9%a1%8c class=hb-docs-link>ÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆÊÄßËÉΩË©ï‰æ°„Å´„Åä„Åë„ÇãË°®Â±§ÁöÑÁõ∏Èñ¢„ÅÆÂïèÈ°å</a></li><li><a href=#%e7%b5%b5%e7%94%bb%e3%81%ab%e9%96%a2%e3%81%99%e3%82%8b%e8%b3%aa%e5%95%8f%e5%bf%9c%e7%ad%94%e3%81%ae%e3%81%9f%e3%82%81%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e3%82%bb%e3%83%83%e3%83%88 class=hb-docs-link>ÁµµÁîª„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆ„Åü„ÇÅ„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà</a></li></ul></li></ul></div></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/>Publications
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/ramos-2025-nada/>No Annotations for Object Detection in Art through Stable Diffusion</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/liu-2025-paladin/>PALADIN: Understanding Video Intentions in Political Advertisement Videos</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/guan-2024-crossmodal/>Cross-modal Guided Visual Representation Learning for Social Image Retrieval</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wang-2024-direct/>DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/hirota-2024-from/>From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/chen-2024-learning/>Learning More May Not Be Better: Knowledge Transferability in Vision-and-Language Tasks</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/hirota-2024-resampled/>Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/hirota-2024-apicture/>A picture may be worth a hundred words for visual question answering</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/qian-2024-cardiovascular/>Is cardiovascular risk profiling from UK Biobank retinal images using explicit deep learning estimates of traditional risk factors equivalent to actual risk measurements? A prospective cohort study design</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/zhang-2024-microemo/>MicroEmo: Time-Sensitive Multimodal Emotion Recognition with Subtle Clue Dynamics in Video Dialogues</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wu-2024-exposed/>Stable Diffusion Exposed: Gender Bias from Prompt to Image</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/pang-2024-videosummary/>Unleashing the Power of Contrastive Learning for Zero-Shot Video Summarization</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/katirai-2024-socialissues/>Situating the social issues of image generation models in the model life cycle: a sociotechnical approach</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/leu-2024-auditingnsfw/>Auditing Image-based NSFW Classifiers for Content Filtering</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/chen-2024-emotional/>Exploring Emotional Stimuli Detection in Artworks: A Benchmark Dataset and Baselines Evaluation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wu-2024-goya/>GOYA: Leveraging Generative Art for Content-Style Disentanglement</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/chen-2024-future/>Would Deep Generative Models Amplify Bias in Future Models?</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wu-2025-reproducibility/>Reproducibility Companion Paper: Stable Diffusion for Content-Style Disentanglement in Art Analysis</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/chen-2024-emotion/>Retrieving Emotional Stimuli in Artworks</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/zhang-2024-instruct/>Instruct me more! Random prompting for visual in-context learning</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/pang-2024-revisiting/>Revisiting pixel-level contrastive pre-training on scene images</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2024-bias/>Societal Bias in Vision-and-Language Datasets and Models</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/okita-2023-atlantoaxial/>Automatic evaluation of atlantoaxial subluxation in rheumatoid arthritis by a deep learning model</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/zhao-2023-fakenews/>Enhancing Fake News Detection in Social Media via Label Propagation on Cross-Modal Tweet Graph</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/teshima-2023-actg/>ACT2G: Attention-based Contrastive Learning for Text-to-Gesture Generation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wang-2023-learning/>Learning bottleneck concepts in image classification</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/hirota-2023-model/>Model-agnostic gender debiased image captioning</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/yang-2023-multi/>Multi-modal humor segment prediction in video</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wu-2023-notonly/>Not only generative art: Stable diffusion for content-style disentanglement in art analysis</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2023-toward/>Toward verifiable and reproducible human evaluation for text-to-image generation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/garcia-2023-uncurated/>Uncurated image-text datasets: Shedding light on demographic bias</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wang-2023-realtime/>Real-time estimation of the remaining surgery duration for cataract surgery using deep convolutional neural networks and long short-term memory</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wang-2024-facade/>Improving facade parsing with vision transformers and line integration</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/goto-2023-development/>Development of a vertex finding algorithm using recurrent neural network</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/lemarchant-2023-inference/>Inference Time Evidences of Adversarial Attacks for Forensic on Transformers</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/pang-2023-contrastive/>Contrastive Losses Are Natural Criteria for Unsupervised Video Summarization</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/suzuki-2022-emotional/>Emotional Intensity Estimation based on Writer‚Äôs Personality</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/teshima-2022-deep/>Deep Gesture Generation for Social Robots Using Type-Specific Libraries</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/tanaka-2022-corpus/>Corpus Construction for Historical Newspapers: A Case Study on Public Meeting Corpus Construction Using OCR Error Correction</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/kumawat-2021-stft/>Depthwise spatio-temporal STFT convolutional neural networks for human action recognition</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wang-2022-match/>Match them up: Visually explainable few-shot image classification</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/verma-2022-multi/>Multi-label disengagement and behavior prediction in online learning</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/suzuki-2022-japanese/>A Japanese Dataset for Subjective and Objective Sentiment Polarity Classification in Micro Blog Domain</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/togashi-2022-cvpr/>AxIoU: An Axiomatically Justified Measure for Video Moment Retrieval</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/hirota-2022-facct/>Gender and racial bias in visual question answering datasets</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2022-cvpr/>Optimal Correction Cost for Object Detection Evaluation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/hirota-2022-cvpr/>Quantifying Societal Bias Amplification in Image Captioning</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/vo-2022-tone/>Tone Classification for Political Advertising Video using Multimodal Cues</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/virgo-2022-sncs/>Information Extraction from Public Meeting Articles</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/kuang-2022-privacy/>Anonymous identity sampling and reusable synthesis for sensitive face camouflage</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/teshima-2022/>Integration of gesture generation system using gesture library with DIY robot design kit</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/chu-2021-semantic/>The semantic typology of visually grounded paraphrases</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/bai-2021-explain/>Explain me the painting: Multi-topic knowledgeable art description generation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/vaigh-202-gcnboost/>GCNBoost: Artwork Classification by Label Propagation Through a Knowledge Graph</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wang-2021-image/>Image Retrieval by Hierarchy-aware Deep Hashing Based on Multi-task Learning</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/li-2021-scouter/>SCOUTER: Slot attention-based classifier for explainable image recognition</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wu-2021-transferring/>Transferring domain-agnostic knowledge in video question answering</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/qian-2021-built/>Built year prediction from Buddha face with heterogeneous labels</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/hirota-2021-visual/>Visual question answering with textual representations for images</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/verma-2021-learners/>Learners' efficiency prediction using facial behavior analysis</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/shoji-2021/>Museum Experience into a Souvenir: Generating Memorable Postcards from Guide Device Behavior Log</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/sayo-2021-posern/>PoseRN: A 2D pose refinement network for bias-free multi-view 3D human pose estimation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/samaran-2021-attending/>Attending self-attention: A case study of visually grounded supervision in vision-and-language transformers</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/yang-2021-bert/>A comparative study of language Transformers for video question answering</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wang-2021-mtunet/>MTUNet: Few-shot image classification with visual explanations</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/kajiwara-2021-wrime/>WRIME: A new dataset for emotional intensity estimation with subjective and objective annotations</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/wang-2021-noisy/>Noisy-LSTM: Improving temporal awareness for video semantic segmentation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/babaguchi-2021-generation/>Generation and detection of media clones</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/babaguchi-2021-preventing/>Preventing fake information generation against media clone attacks</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/kayatani-2021-laughing/>The laughing machine: Predicting humor in video</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/garcia-2019-contextnet/>ContextNet: Representation and exploration for painting classification and retrieval in context</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/dong-2020-cross/>Cross-lingual visual grounding</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/ohashi-2020-idsou/>IDSOU at WNUT-2020 Task 2: Identification of informative COVID-19 English tweets</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/ashihara-2020-improving/>Improving topic modeling through homophily for legal documents</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2020-uncovering/>Uncovering hidden challenges in query-based video moment retrieval</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2020-visually/>Visually grounded paraphrase identification via gating and phrase localization</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/garcia-2020-dataset/>A dataset and baselines for visual question answering on art</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/huckle-2020/>Demographic Influences on Contemporary Art with Unsupervised Style Embeddings</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/garcia-2020-knowledgea/>Knowledge-based video question answering with unsupervised scene descriptions</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/guo-2020-privacy/>Privacy sensitive large-margin model for face de-identification</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/li-2020-joint/>Joint learning of vessel segmentation and artery/vein classification with post-processing</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/garcia-2020-women/>Knowledge-Based Visual Question Answering in Videos</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/verma-2020-yoga/>Yoga-82: A new dataset for fine-grained classification of human poses</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/tanaka-2020-constructing/>Constructing a public meeting corpus</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/kimura-2020-warmer/>Warmer environments increase implicit mental workload even if learning efficiency is enhanced</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/yang-2020-bert/>BERT representations for video question answering</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/li-2020-iternet/>IterNet: Retinal image segmentation utilizing structural redundancy in vessel networks</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2020-toward/>Toward predicting learners' efficiency for adaptive e-learning</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/alizadeh-2020-video/>Video analytics in blended learning: Insights from learner-video interaction patterns</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/gacria-2020-knowit/>KnowIT VQA: Answering knowledge-based questions about videos</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/yamaguchi-20203-d/>3D image reconstruction from multi-focus microscopic images</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2020-speech/>Speech-driven face reenactment for a video sequence</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/sayo-2019-human/>Human shape reconstruction with loose clothes from partially observed data by pose specific deformation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/ashihara-2019-legal/>Legal information as a complex network: Improving topic modeling through homophily</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2019-adaptive/>Adaptive gating mechanism for identifying visually grounded paraphrases</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/renoust-2019-budaart/>BUDA.ART: A multimodal content-based analysis and retrieval system for Buddha statues</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/ben-2019-historical/>Historical and modern features for Buddha statue classification</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/verma-2019-facial/>Facial expression recognition with skip-connection to leverage low-level features</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/garcia-2019-context/>Context-aware embeddings for automatic art analysis</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2019-rethinking/>Rethinking the evaluation of video summaries</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/shirai-2019-multimodal/>Multimodal learning analytics: Society 5.0 project in Japan</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2018-finding/>Finding important people in a video using deep neural networks with conditional random fields</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/chu-2018-ipara/>iParaphrasing: Extracting visually grounded paraphrases via an image</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/tanaka-2018-iterative/>Iterative applications of image completion with CNN-based failure detection</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/kiura-2018-representing/>Representing a partially observed non-rigid 3D human using eigen-texture and eigen-deformation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/tejerodepablos-2018-summarization/>Summarization of user-generated sports video by using deep action recognition features</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/kawai-2017-augmented/>Augmented reality marker hiding with texture deformation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2017-eigen/>Realtime novel view synthesis with eigen-texture regression</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2017-demo/>Video question answering to find a desired video segment</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/rongsirigul-2017-novel/>Novel view synthesis with light-weight view-dependent texture mapping for a stereoscopic HMD</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2017-video/>Video summarization using textual descriptions for authoring video blogs</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/dayrit-2017-increasing/>Increasing pose comprehension through augmented reality reenactment</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/dayrit-2017-remagicmirroir/>ReMagicMirror: Action learning using human reenactment with the mirror metaphor</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/tejero-2016-flexible/>Flexible human action recognition in depth video sequences using masked joint trajectories</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2016-video/>Video summarization using deep semantic features</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2016-learning/>Learning joint representations of videos and sentences with web image search</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/tejerodepablo-2016-human/>Human action recognition-based video summarization for RGB-D personal sports video</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2016-privacy/>Privacy protection for social video via background estimation and CRF-based videographer's intention modeling</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/katagiri-2016-novel/>Novel View Synthesis Based on View-dependent Texture Mapping with Geometry-aware Color Continuity</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/takehara-20163-d/>3D shape template generation from RGB-D images capturing a moving and deforming object</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2016-evaluating/>Evaluating protection capability for visual privacy information</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2015-facial/>Facial expression preserving privacy protection using image melding</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/otani-2015-textual/>Textual description-based video summarization for video blogs</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2015-ar/>AR image generation using view-dependent geometry modification and texture mapping</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/babaguchi-2015-protection/>Protection and utilization of privacy information via sensing</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/kawai-2014-background/>Background estimation for a single omnidirectional image sequence captured with a moving camera</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/dayrit-2014-free/>Free-viewpoint AR human-motion reenactment based on a single RGB-D video stream</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2013-augmented/>Augmented reality image generation with virtualized real objects using view-dependent texture and geometry</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2013-inferring/>Inferring what the videographer wanted to capture</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/koyama-2013-realtime/>Real-time privacy protection system for social videos using intentionally-captured persons detection</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/koyama-2012-markov/>Markov random field-based real-time detection of intentionally-captured persons</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2012-intended/>Intended human object detection for automatically protecting privacy in mobile video surveillance</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2011-extracting/>Extracting intentionally captured regions using point trajectories</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2011-indoor/>Indoor positioning system using digital audio watermarking</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2011-automatic/>Automatic generation of privacy-protected videos using background estimation</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2010-automatically/>Automatically protecting privacy in consumer generated videos using intended human object detector</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/uegaki-2010-discriminating/>Discriminating intended human objects in consumer videos</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/kaneto-2010-realtime/>Real-time user position estimation in indoor environments using digital watermarking for audio signals</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2010-detecting/>Detecting intended human objects in human-captured videos</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/takehara-2010-digital/>Digital diorama: Sensing-based real-world visualization</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2009-watermarked/>Watermarked movie soundtrack finds the position of the camcorder in a theater</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2007-maximum/>Maximum-likelihood estimation of recording position based on audio watermarking</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2007-determining/>Determining Recording Location Based on Synchronization Positions of Audio watermarking</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/publication/nakashima-2006-estimation/>Estimation of recording location using audio watermarking</a></li></ul></div></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/project/>Projects
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/project/pandas/>Pandas</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/project/pytorch/>PyTorch</a></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/project/scikit/>scikit-learn</a></li></ul></div></li></ul><ul class="flex flex-col gap-1 max-lg:hidden"><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/topics/ethical-ai/>AI„ÅÆ„Éê„Ç§„Ç¢„Çπ„Å®„Åù„ÅÆ‰ΩéÊ∏õ</a></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/topics/agent-by-llms/>Â§ßË¶èÊ®°„É¢„Éá„É´„ÅÆÂøúÁî®</a></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/en/topics/explainable-ai/>Ë™¨ÊòéÂèØËÉΩ„Å™AI</a></li><li class=open><a class="hb-sidebar-custom-link
sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900" href=/en/topics/vision-and-language/>Vision and Language</a></li></ul></div></aside><nav class="hb-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents"><div class="hb-scrollbar text-sm [hyphens:auto] sticky top-16 overflow-y-auto pr-4 pt-6 max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] -mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">On this page</p><ul><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#explain-me-the-painting-%e7%b5%b5%e7%94%bb%e3%81%ae%e8%aa%ac%e6%98%8e%e6%96%87%e7%94%9f%e6%88%90>Explain Me the Painting: ÁµµÁîª„ÅÆË™¨ÊòéÊñáÁîüÊàê</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#%e9%83%a8%e5%88%86%e6%98%a0%e5%83%8f%e6%a4%9c%e7%b4%a2%e3%81%ae%e6%80%a7%e8%83%bd%e8%a9%95%e4%be%a1%e3%81%ab%e3%81%8a%e3%81%91%e3%82%8b%e8%a1%a8%e5%b1%a4%e7%9a%84%e7%9b%b8%e9%96%a2%e3%81%ae%e5%95%8f%e9%a1%8c>ÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆÊÄßËÉΩË©ï‰æ°„Å´„Åä„Åë„ÇãË°®Â±§ÁöÑÁõ∏Èñ¢„ÅÆÂïèÈ°å</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#%e7%b5%b5%e7%94%bb%e3%81%ab%e9%96%a2%e3%81%99%e3%82%8b%e8%b3%aa%e5%95%8f%e5%bf%9c%e7%ad%94%e3%81%ae%e3%81%9f%e3%82%81%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e3%82%bb%e3%83%83%e3%83%88>ÁµµÁîª„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆ„Åü„ÇÅ„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà</a></li></ul>
    
    
  </div></nav><article class="flex w-full min-w-0 min-h-[calc(100vh-var(--navbar-height))] justify-center break-words pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="prose prose-slate lg:prose-xl dark:prose-invert w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12"><div class=mb-1><div class="mt-1.5 flex items-center gap-1 overflow-hidden text-sm text-gray-500 dark:text-gray-400"><div class="whitespace-nowrap transition-colors min-w-[24px] overflow-hidden text-ellipsis hover:text-gray-900 dark:hover:text-gray-100"><a href=https://im.sanken.osaka-u.ac.jp/en/topics/>Research Topics</a></div><svg class="w-3.5 shrink-0" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m8.25 4.5 7.5 7.5-7.5 7.5"/></svg><div class="whitespace-nowrap font-medium text-gray-700 dark:text-gray-100">Vision and Language</div></div></div><div class="content text-base"><h1>Vision and Language</h1><p>Ê∑±Â±§Â≠¶Áøí„ÅÆÁôªÂ†¥‰ª•Êù•„ÄÅVision and Language„ÄÅ„Å§„Åæ„ÇäË¶ñË¶ö„Å®Ëá™ÁÑ∂Ë®ÄË™û„ÇíÊâ±„ÅÜÁ†îÁ©∂„ÅØ„ÄÅ„Ç≥„É≥„Éî„É•„Éº„Çø„Éì„Ç∏„Éß„É≥ÂàÜÈáé„ÇÑËá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜÂàÜÈáé„Å´„Åä„Åë„Çã‰∏≠ÂøÉÁöÑ„Å™„Éà„Éî„ÉÉ„ÇØ„ÅÆ‰∏Ä„Å§„Å®„Å™„Çä„Åæ„Åó„Åü„ÄÇÁîªÂÉè„ÇÑÊò†ÂÉè„ÅÆÊÑèÂë≥„ÇíÁêÜËß£„Åô„Çã„Åì„Å®„Å®„ÄÅ„Åù„Çå„Çâ„ÇíËá™ÁÑ∂Ë®ÄË™û„ÅßË°®Áèæ„Åß„Åç„Çã„Åì„Å®„ÅØ„ÄÅÂº∑„ÅÑÈñ¢ÈÄ£„Åå„ÅÇ„Çã„Å®ËÄÉ„Åà„Çâ„Çå„Åæ„Åô„ÄÇ‰ª•‰∏ã„Åß„ÅØ„ÄÅÂΩìÁ†îÁ©∂ÂÆ§„Åß„ÅÆÂèñ„ÇäÁµÑ„Åø„ÅÆ‰∏Ä‰æã„ÇíÁ¥π‰ªã„Åó„Åæ„ÅôÔºà‰∏ÄÈÉ®„ÄÅChatGPT„Å´„Çà„ÇãÊó•Êú¨Ë™ûË®≥„Åß„ÅôÔºâ„ÄÇ</p><h2 id=explain-me-the-painting-ÁµµÁîª„ÅÆË™¨ÊòéÊñáÁîüÊàê>Explain Me the Painting: ÁµµÁîª„ÅÆË™¨ÊòéÊñáÁîüÊàê</h2><p>ÁµµÁîª„ÇíË¶ã„Å¶„ÄÅ„Äå„Åì„ÅÆ‰ΩúÂìÅ„Å´„ÅØ„Å©„Çì„Å™Áâ©Ë™û„Åå„ÅÇ„Çã„ÅÆ„Å†„Çç„ÅÜÔºü„Äç„Å®ÊÄù„Å£„Åü„Åì„Å®„ÅØ„ÅÇ„Çä„Åæ„Åô„ÅãÔºüÊú¨Á†îÁ©∂„Åß„ÅØ„ÄÅËä∏Ë°ì‰ΩúÂìÅ„Å´ÂØæ„Åô„ÇãÁêÜËß£„ÇíÊ∑±„ÇÅ„ÄÅËä∏Ë°ì„Çí‰∫∫„ÄÖ„Å´„Çà„ÇäË∫´Ëøë„Å™„ÇÇ„ÅÆ„Å®„Åô„Çã„Åü„ÇÅ„Å´„ÄÅÁæéË°ìÁµµÁîª„Å´ÂØæ„Åô„ÇãË™¨ÊòéÊñá„ÇíÁîüÊàê„Åô„ÇãÊû†ÁµÑ„Åø„ÇíÊèêÊ°à„Åó„Åæ„Åô„ÄÇÁèæÂú®„ÅÆ‰∫∫Â∑•Áü•ËÉΩÊäÄË°ì„Çí„ÇÇ„Å£„Å¶„Åó„Å¶„ÇÇ„ÄÅËä∏Ë°ì‰ΩúÂìÅ„Å´ÂØæ„Åó„Å¶ÊÉÖÂ†±Èáè„ÅÆÂ§ö„ÅÑË™¨Êòé„ÇíÁîüÊàê„Åô„Çã„Åì„Å®„ÅØÂõ∞Èõ£„Åß„Åô„ÄÇ„Å®„ÅÑ„ÅÜ„ÅÆ„ÇÇ„ÄÅ„Åù„ÅÆ„Åü„ÇÅ„Å´„ÅØ‰ΩúÂìÅ„ÅÆ„Çπ„Çø„Ç§„É´„ÄÅÂÜÖÂÆπ„ÄÅÊßãÂõ≥„Å™„Å©Ë§áÊï∞„ÅÆÂÅ¥Èù¢„ÇíÁêÜËß£„Åó„Å¶Ë®òËø∞„Åó„ÄÅ„Åï„Çâ„Å´ÁîªÂÆ∂„ÇÑ„Åù„ÅÆÂΩ±Èüø„ÄÅ„Åæ„ÅüÊ≠¥Âè≤ÁöÑËÉåÊôØ„Å´Èñ¢„Åô„ÇãÁü•Ë≠ò„ÇÇ‰ªò„ÅëÂä†„Åà„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„Åã„Çâ„Åß„Åô„ÄÇ</p><p>Êú¨Á†îÁ©∂„Åß„ÅØ„Éû„É´„ÉÅ„Éà„Éî„ÉÉ„ÇØ„Åã„Å§Áü•Ë≠ò„Å´Âü∫„Å•„ÅÑ„Åü„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÇíÂ∞éÂÖ•„Åó„Åæ„Åô„ÄÇ„Åì„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„ÅØ„ÄÅÁîüÊàê„Åï„Çå„ÇãÊñáÁ´†„Çí3„Å§„ÅÆËä∏Ë°ìÁöÑ„Éà„Éî„ÉÉ„ÇØ„Å´Ê≤ø„Å£„Å¶ÊßãÊàê„Åó„ÄÅ„Åï„Çâ„Å´Â§ñÈÉ®Áü•Ë≠ò„ÇíÊ¥ªÁî®„Åó„Å¶ÂêÑË™¨Êòé„ÇíÂº∑Âåñ„Åó„Åæ„Åô„ÄÇÊú¨„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅØ„ÄÅÂÆöÈáèÁöÑ„Åä„Çà„Å≥ÂÆöÊÄßÁöÑ„Å™Ë©ï‰æ°„ÄÅ„Åï„Çâ„Å´‰∫∫Èñì„Å´„Çà„ÇãÊØîËºÉË©ï‰æ°„Å´„Åä„ÅÑ„Å¶„ÄÅ„Éà„Éî„ÉÉ„ÇØ„ÅÆÂ§öÊßòÊÄß„Åä„Çà„Å≥ÊÉÖÂ†±„ÅÆÊ≠£Á¢∫ÊÄß„ÅÆ‰∏°Èù¢„ÅßÂÑ™„Çå„ÅüÁµêÊûú„ÇíÁ§∫„Åó„Åæ„Åó„Åü„ÄÇ</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/lRtyhIHyZFw?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><p>Ë©≥Á¥∞„Å®„Ç≥„Éº„Éâ„ÅØ<a href=https://sites.google.com/view/art-description-generation target=_blank rel=noopener>„Åì„Å°„Çâ„ÅÆ„Éö„Éº„Ç∏</a>„Åã„Çâ„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇ</p><h2 id=ÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆÊÄßËÉΩË©ï‰æ°„Å´„Åä„Åë„ÇãË°®Â±§ÁöÑÁõ∏Èñ¢„ÅÆÂïèÈ°å>ÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆÊÄßËÉΩË©ï‰æ°„Å´„Åä„Åë„ÇãË°®Â±§ÁöÑÁõ∏Èñ¢„ÅÆÂïèÈ°å</h2><p>Ëá™ÁÑ∂Ë®ÄË™û„ÇØ„Ç®„É™„Å´„Çà„ÇãÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„Å®„ÅØ„ÄÅÊò†ÂÉè„ÅÆ‰∏≠„Åã„Çâ„ÇØ„Ç®„É™„Å´ÂØæÂøú„Åô„ÇãÈÉ®ÂàÜÊò†ÂÉè„ÇíÁâπÂÆö„ÉªÊäΩÂá∫„Åô„Çã„Çø„Çπ„ÇØ„Åß„Åô„ÄÇ
Ëá™ÁÑ∂Ë®ÄË™û„Å®Êò†ÂÉè„ÅÆ‰∏°Êñπ„ÅÆÊÑèÂë≥„ÇíÁêÜËß£„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„Åü„ÇÅ„ÄÅÈùûÂ∏∏„Å´Èõ£ÊòìÂ∫¶„ÅÆÈ´ò„ÅÑ„Çø„Çπ„ÇØ„Å†„Å®Ë®Ä„Åà„Åæ„Åô„ÄÇ‰ªñ„ÅÆÂ§ö„Åè„ÅÆ„Ç≥„É≥„Éî„É•„Éº„Çø„Éì„Ç∏„Éß„É≥„ÇÑÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂàÜÈáé„ÅÆÊßò„ÄÖ„Å™„Çø„Çπ„ÇØ„Å®ÂêåÊßò„Å´„ÄÅÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆÈÄ≤Â±ï„ÅØ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÊîØ„Åà„Çâ„Çå„Å¶„Åä„Çä„ÄÅ„Åù„Çå„ÇÜ„Åà„Å´„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË≥™„Åå„Åì„ÅÆ„Çø„Çπ„ÇØ„Å´Âèñ„ÇäÁµÑ„ÇÄÁ†îÁ©∂„Ç≥„Éü„É•„Éã„ÉÜ„Ç£ÂÖ®‰Ωì„Å´Â§ß„Åç„Å™ÂΩ±Èüø„Çí‰∏é„Åà„Åæ„Åô„ÄÇ</p><p>ÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„Çø„Çπ„ÇØ„Å´„Åä„ÅÑ„Å¶„ÅØÔºà‰ªñ„ÅÆ„Çø„Çπ„ÇØ„Å®ÂêåÊßò„Å´ÔºâÊßò„ÄÖ„Å™„É¢„Éá„É´„ÅåÊèêÊ°à„Åï„Çå„ÄÅ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„ÅÆ„É©„É≥„Ç≠„É≥„Ç∞„Åå„Å©„Çì„Å©„ÇìÊõ¥Êñ∞„Åï„Çå„Å¶„Åç„Åæ„Åó„Åü„ÄÇÊú¨Á†îÁ©∂„Åß„ÅØ„ÄÅ„Åì„ÅÆ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„ÅÆÁµêÊûú„Åå„ÄÅÂÆüÈöõ„ÅÆ„É¢„Éá„É´„ÅÆÊÄßËÉΩ„Çí„Å©„Çå„Å†„ÅëÊ≠£Á¢∫„Å´ÂèçÊò†„Åó„Å¶„ÅÑ„Çã„Åã„ÇíÂÆüÈ®ìÁöÑ„Å´Á§∫„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„ÇÇ„Åó„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Åå„É¢„Éá„É´„ÇíÊ≠£„Åó„ÅèË©ï‰æ°„Åß„Åç„Å¶„ÅÑ„Å™„ÅÑ„Å®„Åô„Çå„Å∞„ÄÅÂ§ß„Åç„Å™ÂïèÈ°å„Åß„Åô„ÄÇÂÆüÈ®ìÁµêÊûú„Åã„Çâ„ÅØ„ÄÅÂ∫É„Åè‰Ωø„Çè„Çå„Çã„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´„ÅØÂ§ß„Åç„Å™„Éê„Ç§„Ç¢„Çπ„ÅåÂÜÖÂåÖ„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®„ÄÅ„Åï„Çâ„Å´ÂΩìÊôÇ„ÅÆÊúÄÊñ∞„É¢„Éá„É´„ÅØ„Åì„ÅÆ„Éê„Ç§„Ç¢„Çπ„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Åì„Å®„ÅåÁñë„Çè„Çå„ÇãÊåôÂãï„ÅåÊòé„Çâ„Åã„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ</p><p>Âä†„Åà„Å¶„ÄÅÊú¨Á†îÁ©∂„Åß„ÅØÊñ∞„Åü„Å™„Çµ„Éã„ÉÜ„Ç£„ÉÅ„Çß„ÉÉ„ÇØÔºàÂ¶•ÂΩìÊÄßÁ¢∫Ë™çÔºâÂÆüÈ®ì„ÇÑ„ÄÅÁµêÊûú„ÇíË¶ñË¶öÁöÑ„Å´ÁêÜËß£„Åô„Çã„Åü„ÇÅ„ÅÆ„Ç¢„Éó„É≠„Éº„ÉÅ„ÇÇÊèêÊ°à„Åô„Çã„Å®„Å®„ÇÇ„Å´„ÄÅÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆË©ï‰æ°ÊñπÊ≥ï„ÇíÊîπÂñÑ„Åô„Çã„Åü„ÇÅ„ÅÆÊñπÂêëÊÄß„Å´„Å§„ÅÑ„Å¶„ÇÇÊèêÊ°à„Åó„Åæ„Åô„ÄÇ</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/4xYcR42atws?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><p>Ë©≥Á¥∞„Å®„Ç≥„Éº„Éâ„ÅØ<a href=https://mayu-ot.github.io/hidden-challenges-MR/ target=_blank rel=noopener>„Åì„Å°„Çâ„ÅÆ„Éö„Éº„Ç∏</a>„Åã„Çâ„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇ</p><h2 id=ÁµµÁîª„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆ„Åü„ÇÅ„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà>ÁµµÁîª„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆ„Åü„ÇÅ„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà</h2><p>Ëä∏Ë°ì‰ΩúÂìÅÔºàÁµµÁîªÔºâ„Å´Èñ¢„Åô„ÇãË≥™Âïè„Å´Á≠î„Åà„Çã„Åì„Å®„ÅØ‰∫∫Â∑•Áü•ËÉΩ„Å´„Å®„Å£„Å¶Âõ∞Èõ£„Å™Ë™≤È°å„Åß„Åô„ÄÇ„Å™„Åú„Å™„Çâ„ÄÅÂ§ö„Åè„ÅÆÂ†¥Âêà„ÄÅÁµµÁîª„Å´„Å§„ÅÑ„Å¶‰Ωï„ÅãË≥™Âïè„Åô„Çã„Å®„Åç„ÅØ„ÄÅ„Åù„Åì„Å´Êèè„Åã„Çå„ÅüË¶ñË¶öÁöÑ„Å™ÊÉÖÂ†±„Å†„Åë„Åß„Å™„Åè„ÄÅÁæéË°ìÂè≤„ÅÆÂ≠¶Áøí„ÇíÈÄö„Åò„Å¶Âæó„Çâ„Çå„Çã„Åù„ÅÆÁµµÁîª„Å´Èñ¢„Åô„Çã„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„ÅÆÁêÜËß£„ÅåÊ±Ç„ÇÅ„Çâ„Çå„Çã„Åã„Çâ„Åß„Åô„ÄÇ</p><p>Êú¨Á†îÁ©∂„Åß„ÅØ„ÄÅËä∏Ë°ì„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆ„Åü„ÇÅ„ÅÆÊñ∞„Åü„Å™„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÊßãÁØâ„Å´Âêë„Åë„ÅüÂàù„ÅÆË©¶„Åø„Å®„Åó„Å¶„ÄÅAQUA (Art QUestion Answering) „Å®„ÅÑ„ÅÜ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇ„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË≥™ÂïèÂøúÁ≠îÔºàQAÔºâ„Éö„Ç¢„ÅØ„ÄÅÊó¢Â≠ò„ÅÆÁæéË°ìÁêÜËß£„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´Âê´„Åæ„Çå„ÇãÁµµÁîª„Å®„Ç≥„É°„É≥„Éà„Å´Âü∫„Å•„Åç„ÄÅÊúÄÂÖàÁ´Ø„ÅÆË≥™ÂïèÁîüÊàêÊäÄË°ì„ÇíÁî®„ÅÑ„Å¶Ëá™ÂãïÁîüÊàê„Åï„Çå„Åæ„Åô„ÄÇÁîüÊàê„Åï„Çå„ÅüQA„Éö„Ç¢„ÅØ„ÄÅÊñáÊ≥ï„ÅÆÊ≠£Á¢∫„Åï„ÄÅË≥™Âïè„Å∏„ÅÆÂõûÁ≠îÂèØËÉΩÊÄß„ÄÅ„Åù„Åó„Å¶ÁîüÊàê„Åï„Çå„ÅüÂõûÁ≠î„ÅÆÊ≠£„Åó„Åï„ÇíÂü∫Ê∫ñ„Å®„Åó„Å¶„ÄÅ„ÇØ„É©„Ç¶„Éâ„ÇΩ„Éº„Ç∑„É≥„Ç∞„Å´„Çà„Å£„Å¶„ÇØ„É¨„É≥„Ç∏„É≥„Ç∞„Åï„Çå„Å¶„Åä„Çä„ÄÅÈ´òÂìÅË≥™„Å™„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÊú¨„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØË¶ñË¶öÁöÑÔºàÁµµÁîª„Å´Âü∫„Å•„ÅèÔºâË≥™Âïè„Å®Áü•Ë≠òÁöÑÔºà„Ç≥„É°„É≥„Éà„Å´Âü∫„Å•„ÅèÔºâË≥™Âïè„ÅÆ‰∏°Êñπ„ÇíÂê´„Çì„Åß„ÅÑ„Åæ„Åô„ÄÇ</p><p>„Åï„Çâ„Å´„ÄÅË¶ñË¶öÁöÑË≥™Âïè„Å®Áü•Ë≠òÁöÑË≥™Âïè„Çí„Åù„Çå„Åû„ÇåÁã¨Á´ã„Å´Âá¶ÁêÜ„Åô„Çã„Éô„Éº„Çπ„É©„Ç§„É≥„É¢„Éá„É´„ÇÇÊèêÊ°à„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇÊú¨Á†îÁ©∂„Åß„ÅØ„ÄÅ„Åì„ÅÆ„Éô„Éº„Çπ„É©„Ç§„É≥„É¢„Éá„É´„ÇíÁîªÂÉè„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠îÂàÜÈáé„ÅÆÊúÄÂÖàÁ´Ø„É¢„Éá„É´„Å®ÊØîËºÉ„Åó„ÄÅËä∏Ë°ìÂàÜÈáé„Å´„Åä„Åë„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆË™≤È°å„ÇÑ‰ªäÂæå„ÅÆÂèØËÉΩÊÄß„Å´„Å§„ÅÑ„Å¶ÂåÖÊã¨ÁöÑ„Å´Ê§úË®é„Åó„Åæ„Åó„Åü„ÄÇ</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/I78SoOkH3dM?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div></div><time class="mt-12 mb-8 block text-xs text-gray-500 ltr:text-right rtl:text-left dark:text-gray-400" datetime=2023-10-24T00:00:00.000Z><span>Last updated on</span>
Oct 24, 2023</time><div class="pt-1 no-prose w-full"><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex flex-col md:flex-row flex-nowrap justify-between gap-5 pt-2"><div><a class="group flex no-underline" href=/en/topics/explainable-ai/><span class="mt-[-0.3rem] me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Ë™¨ÊòéÂèØËÉΩ„Å™AI</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">Mar 1, 2025</span></span></a></div><div></div></div></div></main></article></div></div><div class=page-footer><footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200"><div class="mx-auto flex gap-3 py-2 px-4"><div class=font-bold><svg class="inline-block pr-1" style="height:1em" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M12 21a9.004 9.004.0 008.716-6.747M12 21a9.004 9.004.0 01-8.716-6.747M12 21c2.485.0 4.5-4.03 4.5-9S14.485 3 12 3m0 18c-2.485.0-4.5-4.03-4.5-9S9.515 3 12 3m0 0a8.997 8.997.0 017.843 4.582M12 3A8.997 8.997.0 004.157 7.582m15.686.0A11.953 11.953.0 0112 10.5c-2.998.0-5.74-1.1-7.843-2.918m15.686.0A8.959 8.959.0 0121 12c0 .778-.099 1.533-.284 2.253m0 0A17.919 17.919.0 0112 16.5a17.92 17.92.0 01-8.716-2.247m0 0A9.015 9.015.0 013 12c0-1.605.42-3.113 1.157-4.418"/></svg>Languages:</div><div class=font-bold>English</div><div><a href=https://im.sanken.osaka-u.ac.jp/ja/topics/vision-and-language/>Êó•Êú¨Ë™û</a></div></div><p class="powered-by text-center">¬© 2025 Â§ßÈò™Â§ßÂ≠¶ Áî£Ê•≠ÁßëÂ≠¶Á†îÁ©∂Áßë Á¨¨‰∏ÄÁ†îÁ©∂ÈÉ®ÈñÄ Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂàÜÈáé</p><p class="powered-by text-center">Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a> ‚Äî the free, <a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></body></html>