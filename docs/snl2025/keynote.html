
<!DOCTYPE html>
<html lang="ja" itemscope itemtype="http://schema.org/WebPage">
  <head>
    <meta charset="UTF-8">
    <meta name="description" content=" Home Invited Speakers Important Dates--...">
    <title>SNL2025 - Symbolic-Neural Learning</title>
    <!-- Open Graph Protocol -->
    <meta property="og:type" content="article">
    <meta property="og:locale" content="ja_JP">
    <meta property="og:title" content="SNL2025">
    <meta property="og:url" content="https://www.airc.aist.go.jp/snl/.html">
    <meta property="og:description" content=" Home Invited Speakers Important Dates--...">
    <meta property="og:site_name" content="Symbolic-Neural lLearning">
    <meta property="og:image" content="https://www.airc.aist.go.jp/mt-static/support/theme_static/rainier/img/siteicon-sample.png">
    <!-- Metadata -->
    <link itemprop="url" href="https://www.airc.aist.go.jp/snl/snl2024.html">
  </head>
  <body>
    <html>
<head>
<meta http-equiv="Content-Language" content="en-us">
</head>
<body>
<font face="arial">

<table width="900">
<tbody>
<tr>
<td valign="top">
<table width="200" bordercolor="#FFFFFF" rules="rows" style="float:left;margin:10px;">
<tbody>
<tr>
<td bgcolor="#656565" id="texture" width="108" height="35" align="left" style="padding: 0px 10px"><span style="font-family: arial;"><a href="/snl2025/index.html" style="text-decoration:none;"><font color="#FFFFFF">Home</font></a></span></td>
</tr>
<tr>
<td bgcolor="#656565" id="texture" width="108" height="35" align="left" style="padding: 0px 10px"><span style="font-family: arial;"><a href="/snl2025/keynote.html" style="text-decoration:none;"><font color="#FFFFFF">Invited Speakers</font></a></span></td>
</tr>
<!--<tr>
<td bgcolor="#656565" id="texture" width="108" height="35" align="left" style="padding: 0px 10px"><span style="font-family: arial;"><a href="https://www.airc.aist.go.jp/snl/dates2024.html" style="text-decoration:none;"><font color="#FFFFFF">Important Dates</font></a></span></td>-->
</tr>
<tr>
<td bgcolor="#656565" id="texture" width="108" height="35" align="left" style="padding: 0px 10px"><span style="font-family: arial;"><a href="/snl2025/submissions.html" style="text-decoration:none;"><font color="#FFFFFF">Submissions</font></a></span></td>
</tr>
<tr>
<td bgcolor="#656565" id="texture" width="108" height="35" align="left" style="padding: 0px 10px"><span style="font-family: arial;"><a href="/snl2025/program.html" style="text-decoration:none;"><font color="#FFFFFF">Program</font></a></span></td>
</tr>
<tr>
<td bgcolor="#656565" id="texture" width="108" height="35" align="left" style="padding: 0px 10px"><span style="font-family: arial;"><a href="/snl2025/venue.html" style="text-decoration:none;"><font color="#FFFFFF">Venue</font></a></span></td>
</tr>
<tr>
<td bgcolor="#656565" id="texture" width="108" height="35" align="left" style="padding: 0px 10px"><span style="font-family: arial;"><a href="/snl2025/registration.html" style="text-decoration:none;"><font color="#FFFFFF">Registration</font></a></span></td>
</tr>
<!--
	<tr>
<td bgcolor="#656565" id=texture height="35" width="108" align="left"  style="padding: 0px 10px"><a target="main_frame" href="committees.htm" style="text-decoration:none;"><font 

face="ヒラギノ角ゴ ProN" color="#FFFFFF">Committees (TBD)</font></a></td>
	</tr>
-->
<tr>
<td bgcolor="#656565" id="texture" width="108" height="35" align="left" style="padding: 0px 10px"><span style="font-family: arial;"><a href="/snl2025/contact.html" style="text-decoration:none;"><font color="#FFFFFF">Contact / Privacy Policy</font></a></span></td>
</tr>
</table>
<table width="200" bordercolor="white" style="float:left;margin:0px;">
  <!--<tr>-->
  <td width="108" valign="bottom" height="40" align="left"><span style="font-family: arial;"><b>Supported by</b></span></td>
  <!--</tr>-->
  
  <tr>
  <td width="108" height="20" align="center"><font face="arial"></font>
  <img alt="TTIJ.jpg" src="/snl2025/img/75c34aae0c77410d1b2eaee77e9c41d2193f9e09.jpg" height="74" border="0" class="mt-image-none" style="" />
  &nbsp; 
  <img alt="TTIC.jpg" src="/snl2025/img/f488cd9cf878dffd5005da4580efc5e48020f8f4.jpg" height="74" border="0">
    </td></tr>
    <tr>
      <td width="108" height="20" align="center" style="vertical-align: middle"><font face="arial"></font>
        &nbsp;&nbsp; <img alt="AIP.jpg" src="/snl2025/img/094eed9dca5024480be142bd3412453ea0e556f4.jpg" height="36" border="0" style="vertical-align: middle">
        &nbsp;&nbsp;&nbsp; <img alt="AIRC.png" src="/snl2025/img/5b9d4aaa4b4a23499342b82b1390bed1dad62ffb.png" height="74" border="0" style="vertical-align: middle">
    </td></tr>
  
  <!--<tr>
  <td width="108" valign="bottom" height="40" align="left"><span style="font-family: arial;"><b>Additional cooperation from</b></span></td>
  </tr>-->
  <tr>
  <td width="108" height="40" align="center"><span style="font-family: arial;"></span>  
  <img alt="tokyotech2.png" src="/snl2025/img/ScienceTokyo_LOGO-A_RGB_S.png" width="90%" border="0" />  
  <img alt="logo_A.jpg" src="/snl2025/img/RGB_JP_EN_A_Handai_Blue.png" height="73" border="0" /><br /> 
    <!--<img alt="ISM2.jpg" src="/snl2025/img/15911ad2c67a6e903db79d2add833a0445ff6689.jpg" height="73" border="0" />--></td>
  </tr>
  </tbody>
  </table>
</td>
<td valign="top">
	 <!--	 <iframe name="main_frame" src="main.htm" scrolling="no" width="900" height="3600" frameborder="no">
		Your browser does not support inline frames or is currently configured not to display inline frames.
		  </iframe>
</td>-->
<table width="800">
<h1>Ninth International Workshop on Symbolic-Neural Learning (SNL2025)</h1>

<span style="font-family: arial;"><span style="font-family: arial;"><bf><span style="color: gray; font-size: small;" size="+1">October 29-30, 2025</span></bf> <br /> <bf><span style="color: gray; font-size: small;" size="+1">Nakanoshima Center 10F, The University of Osaka (Osaka, Japan)</span></bf></span></span><hr />


<h2>Keynote Talks</h2>

<p>
<!--<ol type="I">-->
<a name="chen"></a>
<h3>Yun-Nung (Vivian) Chen (National Taiwan University)</h3>
<h3>"Strategizing Conversations: Reasoning for Personalized AI Agents"</h3>
<img src="img/vivian_chen.jpg" width="200"><br><br>
</p>

<p><b>Abstract:</b><br>
This talk explores how to build more intelligent and personalized AI agents by strategizing conversations. We'll show how to use synthetic dialogue simulation to derive effective conversational strategies. By having LLM role-play as simulated customers and sales agents, we can generate and analyze rich behavioral data. We'll introduce a plug-and-play mechanism that allows us to inject these derived strategies directly into an agent's reasoning process. This approach not only improves performance but also enhances an agent's controllability and explainability, making it a practical tool for real-world marketing. Our method offers a scalable way to understand what influences customer engagement and conversion, ultimately enabling us to strategize more effective and successful interactions.
</p>

<p><b>Bio:</b><br/>
Yun-Nung (Vivian) Chen is currently a professor in the Department of Computer Science & Information Engineering at National Taiwan University. She earned her Ph.D. degree from Carnegie Mellon University, where her research interests focus on spoken dialogue systems and natural language processing. She was recognized as the World's Top 2% Scientists in her 2023 impact, the Taiwan Outstanding Young Women in Science and received Google Faculty Research Awards, Amazon AWS Machine Learning Research Awards, MOST Young Scholar Fellowship, and FAOS Young Scholar Innovation Award. Her team was selected to participate in the first Alexa Prize TaskBot Challenge in 2021. Prior to joining National Taiwan University, she worked in the Deep Learning Technology Center at Microsoft Research Redmond. (<a href="http://vivianchen.idv.tw" target="_blank">http://vivianchen.idv.tw</a>)
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="chiang"></a>
<h3>David Chiang (University of Notre Dame)</h3>
<h3>"What Transformers Can and Can't Do: A Logical Approach"</h3>
</p>

<p><b>Abstract:</b><br>
Neural networks are advancing the state of the art in many areas of artificial intelligence, but in many respects remain poorly understood. At a time when new abilities as well as new limitations of neural networks are continually coming to light, a clear understanding of what they can and cannot do is more needed than ever. The theoretical study of transformers, the dominant neural network for sequences, is just beginning, and we have helped to make this into a fruitful and fast-growing area of research. Our particular approach is to explore these questions by relating neural networks to formal logic. We have successfully proven that one variant of transformers, unique-hard attention transformers, are exactly equivalent to the first-order logic of strings with ordering and to linear temporal logic (LTL), which allows numerous expressivity results from logic to be carried over to unique-hard attention transformers. We have also proven that softmax attention transformers, under suitable assumptions about numeric precision, are exactly equivalent to an extension of LTL with counting. Among other things, this predicts that deeper transformers recognize more languages than shallower transformers, which we have confirmed experimentally.
</p>

<p><b>Bio:</b><br/>
TBA
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="ikeuchi"></a>
<h3>Katsushi Ikeuchi (University of Tokyo)</h3>
<h3>TBA</h3>
</p>

<p><b>Abstract:</b><br>
TBA
</p>

<p><b>Bio:</b><br/>
TBA
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="richardson"></a>
<h3>Kyle Richardson (AI2)</h3>
<h3>"Understanding the Logic of Generative AI through Logic and Programming"</h3>
<img src="img/kyle_richardson.jpg" width="200"><br><br>
</p>

<p><b>Abstract:</b><br>
Symbolic logic has long served as the de facto language for expressing complex knowledge throughout computer science, owing to its clean semantics. Symbolic approaches to reasoning that are driven by declarative knowledge, in sharp contrast to purely machine learning-based approaches, have the advantage of allowing us to reason transparently about the behavior and correctness of the resulting systems. In this talk, we focus on the broad question: Can the declarative and symbolic approaches be leveraged to better understand and formally specify algorithms for large language models (LLMs)? In the first part of the talk, we will focus on formalizing recent direct preference alignment (DPA) loss functions, such as DPO, that are commonly used for LLM alignment. Specifically, we ask: Given an existing DPA loss, can we systematically decompile it into a high-level symbolic program that characterizes its semantics? We outline a novel formalism we developed for this purpose based on probabilistic logic. We discuss how this formal view of preference learning sheds new light on both the size and the structure of the DPA loss landscape and makes it possible to derive new algorithms from first principles. In the second part, we extend this analysis to distilling test-time inference algorithms (e.g., chain-of-thought prompting) into other forms of symbolic programs, ones that rely on a shared set of algorithmic and semantic tools drawn from probabilistic programming and neuro-symbolic modeling. Our general framework and approach aim not only to provide guidance for the AI alignment community, but also to open the door to the development of new high-level programming languages and tooling that make LLM development easier and more transparent.
</p>

<p><b>Bio:</b><br/>
Kyle Richardson is a senior research scientist at the Allen Institute for AI (AI2) in Seattle. He works at the intersection of NLP and Machine Learning on the Aristo team, with a particular focus on generative AI and language models. Recently, he has been interested in using formal methods to better understand and specify algorithms for large language models. Prior to AI2 he was at the IMS and the University of Stuttgart, where he obtained his PhD in 2018. website: <a href="https://www.krichardson.me/" target="_blank">https://www.krichardson.me/</a>
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="walter"></a>
<h3>Matt Walter (Toyota Technological Institute at Chicago)</h3>
<h3>TBA</h3>
</p>

<p><b>Abstract:</b><br>
TBA
</p>

<p><b>Bio:</b><br/>
TBA
</p>
<br/><br/>
</p>
<hr>
<h2>Invited Talks</h2>

<p>
<!--<ol type="I">-->
<a name="bono"></a>
<h3>Mayumi Bono	(National Institute of Informatics)</h3>
<h3>TBA</h3>
</p>

<p><b>Abstract:</b><br>
TBA
</p>

<p><b>Bio:</b><br/>
TBA
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="koutaki"></a>
<h3>Gou Koutaki	(Kumamoto University)</h3>
<h3>"Ensemble System Using Semi-Automatic Instrument-Playing Robots"</h3>
</p>

<p><b>Abstract:</b><br>
The presenter has been developing devices that assist with musical
instrument playing motions. While fully automatic playing robots have been extensively researched, they leave no room for human interaction in the performance. In contrast, this research has developed a semi-automatic instrument device where only part of the playing motions are automated by a robot, while the remaining motions are performed physically by the human player. This allows users to experience physical sound while easily playing their favorite songs. Furthermore, using multiple instrument-playing robots enables ensemble performance. This expands the scope to multi-person interaction. The presenter will introduce the guitar robot and saxophone robot developed. An example of a robot saxophone quartet system featuring soprano, alto, tenor, and baritone saxophones will be presented.
</p>

<p><b>Bio:</b><br/>
Gou Koutaki received a Doctor of Engineering from Kumamoto University, Japan, in 2007. He joined the Production Engineering Research Laboratory, Hitachi, Ltd., in 2007 and is currently a professor at Kumamoto University. His research interests include image processing and musical-instrument support systems. He was originally a researcher in computer vision and has presented papers at CVPR, ICCV, SIGGRAPH technical paper, IJCV, etc., but is currently designing and manufacturing robotic instruments.
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="matsubara"></a>
<h3>Takashi Matsubara	(Hokkaido University)</h3>
<h3>"How First-order Logic Helps Diffusion-based Image Generation"</h3>
</p>

<p><b>Abstract:</b><br>
Despite the remarkable progress of diffusion models in text-to-image generation, they often struggle to faithfully capture the intended meaning of text prompts. A specified object may not appear, an adjective may incorrectly modify unintended objects, or an agent may fail to possess a specified object. In this talk, I introduce Predicated Diffusion, a unified framework designed to more effectively convey user intentions. It represents the intended meaning as propositions in first-order logic and interprets pixels in attention maps as fuzzy predicates. This formulation guides the generation process so that the resulting images more faithfully satisfy the specified propositions.
</p>
<p><b>Bio:</b><br/>
Takashi Matsubara is a Professor at the Graduate School of Information Science and Technology, Hokkaido University. He received his Ph.D. in Engineering from Osaka University in 2015. He then served as an Assistant Professor at the Graduate School of System Informatics, Kobe University, and later as an Associate Professor at the Graduate School of Engineering Science, Osaka University, before assuming his current position in April 2024. Since May 2025, he has also been a Research Scientist at CyberAgent AI Lab. In 2021, he received the Research and Development Encouragement Award under the Strategic Information and Communications R&D Promotion Programme (SCOPE) from the Ministry of Internal Affairs and Communications. His primary research interests lie in scientific machine learning (SciML) and its applications to computer vision. 
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="matsui"></a>
<h3>Yusuke Matsui	(The University of Tokyo)</h3>
<h3>"Where Learned Data Structures Meet Computer Vision"</h3>
</p>

<p><b>Abstract:</b><br>
Learned data structures are a new type of data structure that enhances the performance of classical data structures, such as B-trees, by leveraging the power of machine learning. Learned data structures have been actively studied in the database field and hold the potential to accelerate many procedures across various domains. However, their capabilities are not yet widely recognized. In this talk, I will explore whether learned data structures can be applied to tasks in computer vision, and also discuss how applications in computer vision may influence learned data structures. In this discussion, I explore the potential of learned data structures, next-generation data structures incorporating machine learning.
</p>

<p><b>Bio:</b><br/>
Yusuke Matsui is a senior assistant professor at the Department of Information and Communication Engineering, Graduate School of Information Science and Technology, The University of Tokyo. He received his Ph.D. in information science and technology from the University of Tokyo in 2016. His research focuses on computer vision, data structures, and machine learning. He is particularly interested in developing foundational technologies for large-scale and high-performance AI systems, including vector databases, retrieval-augmented generation (RAG), and learned data structures.
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="mineshima"></a>
<h3>Koji Mineshima (Keio University)</h3>
<h3>TBA</h3>
</p>

<p><b>Abstract:</b><br>
TBA
</p>

<p><b>Bio:</b><br/>
TBA
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="yokota"></a>
<h3>Tatsuya Yokota (Nagoya Institute of Technology)</h3>
<h3>"Tensor Network Decompositions and Their Applications in Machine Learning"</h3>
</p>

<p><b>Abstract:</b><br>
Matrix and tensor decompositions are classical mathematical models that have been widely used for feature extraction and reconstruction of multidimensional array data. In recent years, tensor network decompositions have emerged as more advanced models, and their applications in machine learning are actively being explored. In this talk, I will introduce the fundamentals of tensor network decompositions, highlight their unique and intriguing characteristics, and present examples of their applications.
</p>

<p><b>Bio:</b><br/>
Tatsuya Yokota received his Ph.D. in Engineering from the Tokyo Institute of Technology, Tokyo, Japan, in 2014. He is currently an Associate Professor in the Department of Computer Science at the Nagoya Institute of Technology, Japan, and a Visiting Research Scientist with the Tensor Learning Team at RIKEN AIP. His research interests include matrix and tensor factorizations, signal and image processing, and machine learning. He serves as an Associate Editor for the IEEE Transactions on Signal Processing.
</p>
<br>
<hr>

<p>
<!--<ol type="I">-->
<a name="yokoya"></a>
<h3>Naoto Yokoya (The University of Tokyo, RIKEN)</h3>
<h3>"Open and Equitable AI for Earth Observation"</h3>
</p>

<p><b>Abstract:</b><br>
Machine learning has accelerated the automation and advancement of Earth-observation (EO) analysis. For submeter-resolution imagery, where spatial pattern recognition is central, deep learning is essential, yet openness in data and tools has lagged under restrictive policies. We begin with globally applicable dense-prediction benchmarks: land-cover segmentation built from real, diverse imagery, and height estimation learned with high-fidelity synthetic data and domain adaptation. We then introduce single-image 3D plant reconstruction that combines modeling and machine learning to recover fine structure from one photograph, pointing to extensions from ground to aerial EO. We close with vision–language models for EO and their reliability, with benchmarks for disaster scene understanding and long-term temporal understanding.
</p>

<p><b>Bio:</b><br/>
Naoto Yokoya is a Professor at the University of Tokyo (Graduate School of Frontier Sciences) and leads the Geoinformatics Team at RIKEN AIP. He received his Ph.D. in aerospace engineering from the University of Tokyo in 2013. His research lies at the intersection of remote sensing and computer vision, with applications to disaster management and environmental assessment. He previously held an Alexander von Humboldt Fellowship at DLR/TUM and currently serves as Associate Editor for IEEE TPAMI, IEEE TGRS, and ISPRS JPRS; he is a Clarivate Highly Cited Researcher (2022–).
</p>
<br>
<hr>

<br/>
<p>More invited speakers to be announced!
<br/><br/>
</p>
</table>
</font>
  </body>
</html>
