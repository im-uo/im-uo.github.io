@article{chen2024emotional,
 abstract = {We introduce an emotional stimuli detection task that targets extracting emotional regions that evoke peopleâ€™s emotions (i.e., emotional stimuli) in artworks. This task offers new challenges to the community because of the diversity of artwork styles and the subjectivity of emotions, which can be a suitable testbed for benchmarking the capability of the current neural networks to deal with human emotion. For this task, we construct a dataset called APOLO for quantifying emotional stimuli detection performance in artworks by crowd-sourcing pixel-level annotation of emotional stimuli. APOLO contains 6781 emotional stimuli in 4718 artworks for validation and testing. We also evaluate eight baseline methods, including a dedicated one, to show the difficulties of the task and the limitations of the current techniques through qualitative and quantitative experiments.},
 author = {Tianwei Chen and Noa Garcia and Liangzhi Li and  Yuta Nakashima},
 doi = {https://doi.org/10.3390/jimaging10060136},
 journal = {Journal of Imaging},
 month = {6},
 number = {6},
 pages = {136},
 title = {Exploring Emotional Stimuli Detection in Artworks: A Benchmark Dataset and Baselines Evaluation},
 url = {https://www.mdpi.com/2313-433X/10/6/136},
 volume = {10},
 year = {2024}
}
