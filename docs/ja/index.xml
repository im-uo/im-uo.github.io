<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂÆ§</title><link>https://im.sanken.osaka-u.ac.jp/ja/</link><atom:link href="https://im.sanken.osaka-u.ac.jp/ja/index.xml" rel="self" type="application/rss+xml"/><description>Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂÆ§</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>ja-jp</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate><image><url>https://im.sanken.osaka-u.ac.jp/media/logo_hu_5496ce6447801688.png</url><title>Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂÆ§</title><link>https://im.sanken.osaka-u.ac.jp/ja/</link></image><item><title>‚ú® M1„ÄÅB4„ÅåÈÖçÂ±û„Åï„Çå„Åæ„Åó„Åü</title><link>https://im.sanken.osaka-u.ac.jp/ja/post/newcomers2025/</link><pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/post/newcomers2025/</guid><description>&lt;p>Â§ñÈÉ®ÈÄ≤Â≠¶„ÅÆM1„Åå2Âêç„ÄÅB4„Åå4Âêç„ÄÅ„Éï„É≠„É≥„ÉÜ„Ç£„Ç¢„É©„Éú„ÅÆÂ≠¶Áîü„Åï„Çì„Åå1ÂêçÈÖçÂ±û„Åï„Çå„Åæ„Åó„Åü„ÄÇ‰∏≠Â≥∂Á†î„Å®„Åó„Å¶„ÅØÁ¨¨1ÊúüÁîü„Å®„Å™„Çä„Åæ„Åô„ÄÇ&lt;/p>
&lt;p>Á†îÁ©∂„ÇÇÈÅä„Å≥„ÇÇÊ•Ω„Åó„Çì„Åß„Åè„Å†„Åï„ÅÑÔºÅ&lt;/p></description></item><item><title>üîÑ Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢ÂàÜÈáé„ÅØ„É™„Éã„É•„Éº„Ç¢„É´„Åó„Åæ„Åô</title><link>https://im.sanken.osaka-u.ac.jp/ja/post/renewal/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/post/renewal/</guid><description>&lt;p>ÂÖ´Êú®ÊïôÊéà„ÅÆÈÄÄ‰ªª„Å®‰∏≠Â≥∂„ÅÆÁùÄ‰ªª„Å´‰º¥„ÅÑ„ÄÅÂ§ßÈò™Â§ßÂ≠¶Áî£Ê•≠ÁßëÂ≠¶Á†îÁ©∂ÊâÄÁ¨¨1Á†îÁ©∂ÈÉ®ÈñÄ Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢ÂàÜÈáé„ÅØ2025Âπ¥4Êúà1Êó•„Çà„Çä‰∏≠Â≥∂Á†îÁ©∂ÂÆ§ÔºàMIMLabÔºâ„Å®„Åó„Å¶Ê¥ªÂãï„ÇíÂßã„ÇÅ„Åæ„Åó„Åü„ÄÇ&lt;/p>
&lt;p>ÂÖ´Êú®ÂÖàÁîü„ÅåÁØâ„ÅÑ„ÅüÁ†îÁ©∂ÂÆ§„ÅÆÂü∫Áõ§„ÇíÂºï„ÅçÁ∂ô„Åé„Å§„Å§„ÄÅÊñ∞„Åó„ÅÑÁ†îÁ©∂ÂÆ§„Å®„Åó„Å¶Á†îÁ©∂„ÇÇ„Åù„ÅÆ„Åª„Åã„ÅÆÊ¥ªÂãï„ÇÇÊ•Ω„Åó„Çì„Åß„ÇÇ„Çâ„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ&lt;/p></description></item><item><title>AI„ÅÆ„Éê„Ç§„Ç¢„Çπ„Å®„Åù„ÅÆ‰ΩéÊ∏õ</title><link>https://im.sanken.osaka-u.ac.jp/ja/topics/ethical-ai/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/topics/ethical-ai/</guid><description/></item><item><title>üßë‚Äçüéì ‰∏≠Â≥∂Á†îÁ©∂ÂÆ§ÔºàMIMLabÔºâ„Å∏„ÅÆÈÖçÂ±û„ÇíÂ∏åÊúõ„Åô„ÇãÂ≠¶Áîü„Åï„Çì„Å∏</title><link>https://im.sanken.osaka-u.ac.jp/ja/post/recruit/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/post/recruit/</guid><description>&lt;p>Â§ßÈò™Â§ßÂ≠¶Áî£Ê•≠ÁßëÂ≠¶Á†îÁ©∂ÊâÄÁ¨¨1Á†îÁ©∂ÈÉ®ÈñÄ Ë§áÂêàÁü•ËÉΩ„É°„Éá„Ç£„Ç¢Á†îÁ©∂ÂàÜÈáéÔºà‰∏≠Â≥∂Á†îÁ©∂ÂÆ§„ÄÅMIMLabÔºâ„ÅØ„ÄÅÂ§ßÈò™Â§ßÂ≠¶Â§ßÂ≠¶Èô¢ÊÉÖÂ†±ÁßëÂ≠¶Á†îÁ©∂Áßë„ÅÆÂçîÂäõË¨õÂ∫ß„Å®„Åó„Å¶„ÄÅ&lt;a href="https://www.ics.es.osaka-u.ac.jp/" target="_blank" rel="noopener">Â§ßÈò™Â§ßÂ≠¶Âü∫Á§éÂ∑•Â≠¶ÈÉ®ÊÉÖÂ†±ÁßëÂ≠¶ÁßëË®àÁÆóÊ©üÁßëÂ≠¶„Ç≥„Éº„Çπ„ÄÅ„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢ÁßëÂ≠¶„Ç≥„Éº„Çπ&lt;/a>„ÄÅÂèä„Å≥&lt;a href="https://www.ist.osaka-u.ac.jp/japanese/" target="_blank" rel="noopener">Â§ßÈò™Â§ßÂ≠¶ÊÉÖÂ†±ÁßëÂ≠¶Á†îÁ©∂Áßë&lt;/a>„ÅÆÂ≠¶Áîü„Åï„Çì„ÇíÂèó„ÅëÂÖ•„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ&lt;/p>
&lt;p>Â≠¶ÈÉ®Áîü„Å®„Åó„Å¶ÂΩìÁ†îÁ©∂ÂÆ§„Å∏„ÅÆÈÖçÂ±û„ÇíÂ∏åÊúõ„Åï„Çå„ÇãÂ†¥Âêà„ÅØ„ÄÅÂ§ßÈò™Â§ßÂ≠¶Âü∫Á§éÂ∑•Â≠¶ÈÉ®ÊÉÖÂ†±ÁßëÂ≠¶Áßë„Åã„Çâ„Å´„Å™„Çä„Åæ„ÅôÔºà&lt;a href="https://www.ics.es.osaka-u.ac.jp/exam/" target="_blank" rel="noopener">ÂÖ•Ë©¶ÊÉÖÂ†±&lt;/a>Ôºâ„ÄÇ&lt;/p>
&lt;p>Â§ßÂ≠¶Èô¢Áîü„Å®„Åó„Å¶ÈÖçÂ±û„ÇíÂ∏åÊúõ„Åï„Çå„ÇãÂ†¥Âêà„ÅØ„ÄÅÂ§ßÈò™Â§ßÂ≠¶ÊÉÖÂ†±ÁßëÂ≠¶Á†îÁ©∂„Åã„Çâ„Å®„Å™„Çä„Åæ„ÅôÔºà&lt;a href="https://www.ist.osaka-u.ac.jp/japanese/examinees/" target="_blank" rel="noopener">ÂÖ•Ë©¶ÊÉÖÂ†±&lt;/a>Ôºâ„ÄÇÂçöÂ£´ÂâçÊúüË™≤Á®ã„ÄÅÂçöÂ£´ÂæåÊúüË™≤Á®ã„ÅÑ„Åö„Çå„ÇÇ‰∫ãÂâç„Å´&lt;a href="https://im.sanken.osaka-u.ac.jp/ja/#access">„Åì„Å°„Çâ&lt;/a>„ÅÆ„É°„Éº„É´„Ç¢„Éâ„É¨„ÇπÂÆõ„Å´CV„Å®Á†îÁ©∂ÊèêÊ°àÊõ∏„Çí„ÅäÈÄÅ„Çä„ÅÑ„Åü„Å†„Åë„Çã„Å®„ÄÅ„Çπ„ÇØ„É™„Éº„Éã„É≥„Ç∞„ÄÅÈù¢Ë´á„ÅÆ‰∏ä„Åß„Åï„Åæ„Åñ„Åæ„Å™„Çµ„Éù„Éº„Éà„Åå„Åß„Åç„Çã„Å®ÊÄù„ÅÑ„Åæ„ÅôÔºàCV„Å®Á†îÁ©∂ÊèêÊ°àÊõ∏„ÅØ„Çπ„ÇØ„É™„Éº„Éã„É≥„Ç∞„ÅÆÁõÆÁöÑ„ÅÆ„Åø„ÅßÂà©Áî®„ÅÑ„Åü„Åó„Åæ„ÅôÔºâ„ÄÇ&lt;/p>
&lt;p>ÂΩìÁ†îÁ©∂ÂÆ§„Åß„ÅØ„ÄÅÂ≠¶ÁîüÁîüÊ¥ª„ÇíÊ•Ω„Åó„ÅèÈÅé„Åî„Åó„Å§„Å§„ÄÅÁ†îÁ©∂„Å´ËààÂë≥„ÇíÊåÅ„Å£„Å¶Âèñ„ÇäÁµÑ„Çì„Åß„Åè„Çå„ÇãÂ≠¶Áîü„Åï„Çì„ÇíÊ≠ìËøé„Åó„Åæ„Åô„ÄÇ„Éà„ÉÉ„Éó„Ç´„É≥„Éï„Ç°„É¨„É≥„Çπ„ÇíÁõÆÊåá„Åó„Å¶Á†îÁ©∂„ÇíÈÄ≤„ÇÅ„Åü„ÅÑ„Å®„ÅÑ„ÅÜÁöÜÊßò„ÅØ„ÄÅ„Åú„Å≤ÂΩìÁ†îÁ©∂ÂÆ§„Çí„ÅîÊ§úË®é„Åè„Å†„Åï„ÅÑ„ÄÇ‰∏ÄÊñπ„Åß„ÄÅÁâπ„Å´Â§ßÂ≠¶Èô¢„Åã„Çâ„ÅÆÈÖçÂ±ûÂ∏åÊúõ„ÅÆÂ†¥Âêà„ÅØ„ÄÅ„Åù„Çå„Åæ„Åß„ÅÆÁ†îÁ©∂ÁµåÈ®ì„ÇíÈáçË¶ñ„Åó„Å¶„Çπ„ÇØ„É™„Éº„Éã„É≥„Ç∞„ÇíÂÆüÊñΩ„Åó„Åæ„Åô„ÄÇ&lt;/p>
&lt;p>Ê•Ω„Åó„ÅèÁ†îÁ©∂„Åó„Åü„ÅÑ„ÄÅ„Å®„ÅÑ„ÅÜÂ≠¶Áîü„Åï„Çì„Çí„ÅäÂæÖ„Å°„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ&lt;/p></description></item><item><title>Ë™¨ÊòéÂèØËÉΩ„Å™AI</title><link>https://im.sanken.osaka-u.ac.jp/ja/topics/explainable-ai/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/topics/explainable-ai/</guid><description/></item><item><title>Â§ßË¶èÊ®°„É¢„Éá„É´„ÅÆÂøúÁî®</title><link>https://im.sanken.osaka-u.ac.jp/ja/topics/agent-by-llms/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/topics/agent-by-llms/</guid><description/></item><item><title>No Annotations for Object Detection in Art through Stable Diffusion</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ramos-2025-nada/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ramos-2025-nada/</guid><description/></item><item><title>PALADIN: Understanding Video Intentions in Political Advertisement Videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/liu-2025-paladin/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/liu-2025-paladin/</guid><description/></item><item><title>Cross-modal Guided Visual Representation Learning for Social Image Retrieval</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/guan-2024-crossmodal/</link><pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/guan-2024-crossmodal/</guid><description/></item><item><title>DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2024-direct/</link><pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2024-direct/</guid><description/></item><item><title>From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-from/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-from/</guid><description/></item><item><title>Learning More May Not Be Better: Knowledge Transferability in Vision-and-Language Tasks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-learning/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-learning/</guid><description/></item><item><title>Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-resampled/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-resampled/</guid><description/></item><item><title>A picture may be worth a hundred words for visual question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-apicture/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-apicture/</guid><description/></item><item><title>Is cardiovascular risk profiling from UK Biobank retinal images using explicit deep learning estimates of traditional risk factors equivalent to actual risk measurements? A prospective cohort study design</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/qian-2024-cardiovascular/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/qian-2024-cardiovascular/</guid><description/></item><item><title>MicroEmo: Time-Sensitive Multimodal Emotion Recognition with Subtle Clue Dynamics in Video Dialogues</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/zhang-2024-microemo/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/zhang-2024-microemo/</guid><description/></item><item><title>Stable Diffusion Exposed: Gender Bias from Prompt to Image</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2024-exposed/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2024-exposed/</guid><description/></item><item><title>Unleashing the Power of Contrastive Learning for Zero-Shot Video Summarization</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2024-videosummary/</link><pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2024-videosummary/</guid><description/></item><item><title>Situating the social issues of image generation models in the model life cycle: a sociotechnical approach</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/katirai-2024-socialissues/</link><pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/katirai-2024-socialissues/</guid><description/></item><item><title>Auditing Image-based NSFW Classifiers for Content Filtering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/leu-2024-auditingnsfw/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/leu-2024-auditingnsfw/</guid><description/></item><item><title>Exploring Emotional Stimuli Detection in Artworks: A Benchmark Dataset and Baselines Evaluation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-emotional/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-emotional/</guid><description/></item><item><title>GOYA: Leveraging Generative Art for Content-Style Disentanglement</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2024-goya/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2024-goya/</guid><description/></item><item><title>Would Deep Generative Models Amplify Bias in Future Models?</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-future/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-future/</guid><description/></item><item><title>Reproducibility Companion Paper: Stable Diffusion for Content-Style Disentanglement in Art Analysis</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2025-reproducibility/</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2025-reproducibility/</guid><description/></item><item><title>Retrieving Emotional Stimuli in Artworks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-emotion/</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-emotion/</guid><description/></item><item><title>Instruct me more! Random prompting for visual in-context learning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/zhang-2024-instruct/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/zhang-2024-instruct/</guid><description/></item><item><title>Revisiting pixel-level contrastive pre-training on scene images</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2024-revisiting/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2024-revisiting/</guid><description/></item><item><title>Societal Bias in Vision-and-Language Datasets and Models</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2024-bias/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2024-bias/</guid><description/></item><item><title>Vision and Language</title><link>https://im.sanken.osaka-u.ac.jp/ja/topics/vision-and-language/</link><pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/topics/vision-and-language/</guid><description>&lt;p>Ê∑±Â±§Â≠¶Áøí„ÅÆÁôªÂ†¥‰ª•Êù•„ÄÅVision and Language„ÄÅ„Å§„Åæ„ÇäË¶ñË¶ö„Å®Ëá™ÁÑ∂Ë®ÄË™û„ÇíÊâ±„ÅÜÁ†îÁ©∂„ÅØ„ÄÅ„Ç≥„É≥„Éî„É•„Éº„Çø„Éì„Ç∏„Éß„É≥ÂàÜÈáé„ÇÑËá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜÂàÜÈáé„Å´„Åä„Åë„Çã‰∏≠ÂøÉÁöÑ„Å™„Éà„Éî„ÉÉ„ÇØ„ÅÆ‰∏Ä„Å§„Å®„Å™„Çä„Åæ„Åó„Åü„ÄÇÁîªÂÉè„ÇÑÊò†ÂÉè„ÅÆÊÑèÂë≥„ÇíÁêÜËß£„Åô„Çã„Åì„Å®„Å®„ÄÅ„Åù„Çå„Çâ„ÇíËá™ÁÑ∂Ë®ÄË™û„ÅßË°®Áèæ„Åß„Åç„Çã„Åì„Å®„ÅØ„ÄÅÂº∑„ÅÑÈñ¢ÈÄ£„Åå„ÅÇ„Çã„Å®ËÄÉ„Åà„Çâ„Çå„Åæ„Åô„ÄÇ‰ª•‰∏ã„Åß„ÅØ„ÄÅÂΩìÁ†îÁ©∂ÂÆ§„Åß„ÅÆÂèñ„ÇäÁµÑ„Åø„ÅÆ‰∏Ä‰æã„ÇíÁ¥π‰ªã„Åó„Åæ„ÅôÔºà‰∏ÄÈÉ®„ÄÅChatGPT„Å´„Çà„ÇãÊó•Êú¨Ë™ûË®≥„Åß„ÅôÔºâ„ÄÇ&lt;/p>
&lt;h2 id="explain-me-the-painting-ÁµµÁîª„ÅÆË™¨ÊòéÊñáÁîüÊàê">Explain Me the Painting: ÁµµÁîª„ÅÆË™¨ÊòéÊñáÁîüÊàê&lt;/h2>
&lt;p>ÁµµÁîª„ÇíË¶ã„Å¶„ÄÅ„Äå„Åì„ÅÆ‰ΩúÂìÅ„Å´„ÅØ„Å©„Çì„Å™Áâ©Ë™û„Åå„ÅÇ„Çã„ÅÆ„Å†„Çç„ÅÜÔºü„Äç„Å®ÊÄù„Å£„Åü„Åì„Å®„ÅØ„ÅÇ„Çä„Åæ„Åô„ÅãÔºüÊú¨Á†îÁ©∂„Åß„ÅØ„ÄÅËä∏Ë°ì‰ΩúÂìÅ„Å´ÂØæ„Åô„ÇãÁêÜËß£„ÇíÊ∑±„ÇÅ„ÄÅËä∏Ë°ì„Çí‰∫∫„ÄÖ„Å´„Çà„ÇäË∫´Ëøë„Å™„ÇÇ„ÅÆ„Å®„Åô„Çã„Åü„ÇÅ„Å´„ÄÅÁæéË°ìÁµµÁîª„Å´ÂØæ„Åô„ÇãË™¨ÊòéÊñá„ÇíÁîüÊàê„Åô„ÇãÊû†ÁµÑ„Åø„ÇíÊèêÊ°à„Åó„Åæ„Åô„ÄÇÁèæÂú®„ÅÆ‰∫∫Â∑•Áü•ËÉΩÊäÄË°ì„Çí„ÇÇ„Å£„Å¶„Åó„Å¶„ÇÇ„ÄÅËä∏Ë°ì‰ΩúÂìÅ„Å´ÂØæ„Åó„Å¶ÊÉÖÂ†±Èáè„ÅÆÂ§ö„ÅÑË™¨Êòé„ÇíÁîüÊàê„Åô„Çã„Åì„Å®„ÅØÂõ∞Èõ£„Åß„Åô„ÄÇ„Å®„ÅÑ„ÅÜ„ÅÆ„ÇÇ„ÄÅ„Åù„ÅÆ„Åü„ÇÅ„Å´„ÅØ‰ΩúÂìÅ„ÅÆ„Çπ„Çø„Ç§„É´„ÄÅÂÜÖÂÆπ„ÄÅÊßãÂõ≥„Å™„Å©Ë§áÊï∞„ÅÆÂÅ¥Èù¢„ÇíÁêÜËß£„Åó„Å¶Ë®òËø∞„Åó„ÄÅ„Åï„Çâ„Å´ÁîªÂÆ∂„ÇÑ„Åù„ÅÆÂΩ±Èüø„ÄÅ„Åæ„ÅüÊ≠¥Âè≤ÁöÑËÉåÊôØ„Å´Èñ¢„Åô„ÇãÁü•Ë≠ò„ÇÇ‰ªò„ÅëÂä†„Åà„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„Åã„Çâ„Åß„Åô„ÄÇ&lt;/p>
&lt;p>Êú¨Á†îÁ©∂„Åß„ÅØ„Éû„É´„ÉÅ„Éà„Éî„ÉÉ„ÇØ„Åã„Å§Áü•Ë≠ò„Å´Âü∫„Å•„ÅÑ„Åü„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÇíÂ∞éÂÖ•„Åó„Åæ„Åô„ÄÇ„Åì„ÅÆ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Åß„ÅØ„ÄÅÁîüÊàê„Åï„Çå„ÇãÊñáÁ´†„Çí3„Å§„ÅÆËä∏Ë°ìÁöÑ„Éà„Éî„ÉÉ„ÇØ„Å´Ê≤ø„Å£„Å¶ÊßãÊàê„Åó„ÄÅ„Åï„Çâ„Å´Â§ñÈÉ®Áü•Ë≠ò„ÇíÊ¥ªÁî®„Åó„Å¶ÂêÑË™¨Êòé„ÇíÂº∑Âåñ„Åó„Åæ„Åô„ÄÇÊú¨„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅØ„ÄÅÂÆöÈáèÁöÑ„Åä„Çà„Å≥ÂÆöÊÄßÁöÑ„Å™Ë©ï‰æ°„ÄÅ„Åï„Çâ„Å´‰∫∫Èñì„Å´„Çà„ÇãÊØîËºÉË©ï‰æ°„Å´„Åä„ÅÑ„Å¶„ÄÅ„Éà„Éî„ÉÉ„ÇØ„ÅÆÂ§öÊßòÊÄß„Åä„Çà„Å≥ÊÉÖÂ†±„ÅÆÊ≠£Á¢∫ÊÄß„ÅÆ‰∏°Èù¢„ÅßÂÑ™„Çå„ÅüÁµêÊûú„ÇíÁ§∫„Åó„Åæ„Åó„Åü„ÄÇ&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/lRtyhIHyZFw?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>Ë©≥Á¥∞„Å®„Ç≥„Éº„Éâ„ÅØ&lt;a href="https://sites.google.com/view/art-description-generation" target="_blank" rel="noopener">„Åì„Å°„Çâ„ÅÆ„Éö„Éº„Ç∏&lt;/a>„Åã„Çâ„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇ&lt;/p>
&lt;h2 id="ÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆÊÄßËÉΩË©ï‰æ°„Å´„Åä„Åë„ÇãË°®Â±§ÁöÑÁõ∏Èñ¢„ÅÆÂïèÈ°å">ÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆÊÄßËÉΩË©ï‰æ°„Å´„Åä„Åë„ÇãË°®Â±§ÁöÑÁõ∏Èñ¢„ÅÆÂïèÈ°å&lt;/h2>
&lt;p>Ëá™ÁÑ∂Ë®ÄË™û„ÇØ„Ç®„É™„Å´„Çà„ÇãÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„Å®„ÅØ„ÄÅÊò†ÂÉè„ÅÆ‰∏≠„Åã„Çâ„ÇØ„Ç®„É™„Å´ÂØæÂøú„Åô„ÇãÈÉ®ÂàÜÊò†ÂÉè„ÇíÁâπÂÆö„ÉªÊäΩÂá∫„Åô„Çã„Çø„Çπ„ÇØ„Åß„Åô„ÄÇ
Ëá™ÁÑ∂Ë®ÄË™û„Å®Êò†ÂÉè„ÅÆ‰∏°Êñπ„ÅÆÊÑèÂë≥„ÇíÁêÜËß£„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã„Åü„ÇÅ„ÄÅÈùûÂ∏∏„Å´Èõ£ÊòìÂ∫¶„ÅÆÈ´ò„ÅÑ„Çø„Çπ„ÇØ„Å†„Å®Ë®Ä„Åà„Åæ„Åô„ÄÇ‰ªñ„ÅÆÂ§ö„Åè„ÅÆ„Ç≥„É≥„Éî„É•„Éº„Çø„Éì„Ç∏„Éß„É≥„ÇÑÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂàÜÈáé„ÅÆÊßò„ÄÖ„Å™„Çø„Çπ„ÇØ„Å®ÂêåÊßò„Å´„ÄÅÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆÈÄ≤Â±ï„ÅØ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÊîØ„Åà„Çâ„Çå„Å¶„Åä„Çä„ÄÅ„Åù„Çå„ÇÜ„Åà„Å´„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË≥™„Åå„Åì„ÅÆ„Çø„Çπ„ÇØ„Å´Âèñ„ÇäÁµÑ„ÇÄÁ†îÁ©∂„Ç≥„Éü„É•„Éã„ÉÜ„Ç£ÂÖ®‰Ωì„Å´Â§ß„Åç„Å™ÂΩ±Èüø„Çí‰∏é„Åà„Åæ„Åô„ÄÇ&lt;/p>
&lt;p>ÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„Çø„Çπ„ÇØ„Å´„Åä„ÅÑ„Å¶„ÅØÔºà‰ªñ„ÅÆ„Çø„Çπ„ÇØ„Å®ÂêåÊßò„Å´ÔºâÊßò„ÄÖ„Å™„É¢„Éá„É´„ÅåÊèêÊ°à„Åï„Çå„ÄÅ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„ÅÆ„É©„É≥„Ç≠„É≥„Ç∞„Åå„Å©„Çì„Å©„ÇìÊõ¥Êñ∞„Åï„Çå„Å¶„Åç„Åæ„Åó„Åü„ÄÇÊú¨Á†îÁ©∂„Åß„ÅØ„ÄÅ„Åì„ÅÆ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„ÅÆÁµêÊûú„Åå„ÄÅÂÆüÈöõ„ÅÆ„É¢„Éá„É´„ÅÆÊÄßËÉΩ„Çí„Å©„Çå„Å†„ÅëÊ≠£Á¢∫„Å´ÂèçÊò†„Åó„Å¶„ÅÑ„Çã„Åã„ÇíÂÆüÈ®ìÁöÑ„Å´Á§∫„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„ÇÇ„Åó„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Åå„É¢„Éá„É´„ÇíÊ≠£„Åó„ÅèË©ï‰æ°„Åß„Åç„Å¶„ÅÑ„Å™„ÅÑ„Å®„Åô„Çå„Å∞„ÄÅÂ§ß„Åç„Å™ÂïèÈ°å„Åß„Åô„ÄÇÂÆüÈ®ìÁµêÊûú„Åã„Çâ„ÅØ„ÄÅÂ∫É„Åè‰Ωø„Çè„Çå„Çã„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´„ÅØÂ§ß„Åç„Å™„Éê„Ç§„Ç¢„Çπ„ÅåÂÜÖÂåÖ„Åï„Çå„Å¶„ÅÑ„Çã„Åì„Å®„ÄÅ„Åï„Çâ„Å´ÂΩìÊôÇ„ÅÆÊúÄÊñ∞„É¢„Éá„É´„ÅØ„Åì„ÅÆ„Éê„Ç§„Ç¢„Çπ„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Åì„Å®„ÅåÁñë„Çè„Çå„ÇãÊåôÂãï„ÅåÊòé„Çâ„Åã„Å´„Å™„Çä„Åæ„Åó„Åü„ÄÇ&lt;/p>
&lt;p>Âä†„Åà„Å¶„ÄÅÊú¨Á†îÁ©∂„Åß„ÅØÊñ∞„Åü„Å™„Çµ„Éã„ÉÜ„Ç£„ÉÅ„Çß„ÉÉ„ÇØÔºàÂ¶•ÂΩìÊÄßÁ¢∫Ë™çÔºâÂÆüÈ®ì„ÇÑ„ÄÅÁµêÊûú„ÇíË¶ñË¶öÁöÑ„Å´ÁêÜËß£„Åô„Çã„Åü„ÇÅ„ÅÆ„Ç¢„Éó„É≠„Éº„ÉÅ„ÇÇÊèêÊ°à„Åô„Çã„Å®„Å®„ÇÇ„Å´„ÄÅÈÉ®ÂàÜÊò†ÂÉèÊ§úÁ¥¢„ÅÆË©ï‰æ°ÊñπÊ≥ï„ÇíÊîπÂñÑ„Åô„Çã„Åü„ÇÅ„ÅÆÊñπÂêëÊÄß„Å´„Å§„ÅÑ„Å¶„ÇÇÊèêÊ°à„Åó„Åæ„Åô„ÄÇ&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/4xYcR42atws?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>Ë©≥Á¥∞„Å®„Ç≥„Éº„Éâ„ÅØ&lt;a href="https://mayu-ot.github.io/hidden-challenges-MR/" target="_blank" rel="noopener">„Åì„Å°„Çâ„ÅÆ„Éö„Éº„Ç∏&lt;/a>„Åã„Çâ„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇ&lt;/p>
&lt;h2 id="ÁµµÁîª„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆ„Åü„ÇÅ„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà">ÁµµÁîª„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆ„Åü„ÇÅ„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà&lt;/h2>
&lt;p>Ëä∏Ë°ì‰ΩúÂìÅÔºàÁµµÁîªÔºâ„Å´Èñ¢„Åô„ÇãË≥™Âïè„Å´Á≠î„Åà„Çã„Åì„Å®„ÅØ‰∫∫Â∑•Áü•ËÉΩ„Å´„Å®„Å£„Å¶Âõ∞Èõ£„Å™Ë™≤È°å„Åß„Åô„ÄÇ„Å™„Åú„Å™„Çâ„ÄÅÂ§ö„Åè„ÅÆÂ†¥Âêà„ÄÅÁµµÁîª„Å´„Å§„ÅÑ„Å¶‰Ωï„ÅãË≥™Âïè„Åô„Çã„Å®„Åç„ÅØ„ÄÅ„Åù„Åì„Å´Êèè„Åã„Çå„ÅüË¶ñË¶öÁöÑ„Å™ÊÉÖÂ†±„Å†„Åë„Åß„Å™„Åè„ÄÅÁæéË°ìÂè≤„ÅÆÂ≠¶Áøí„ÇíÈÄö„Åò„Å¶Âæó„Çâ„Çå„Çã„Åù„ÅÆÁµµÁîª„Å´Èñ¢„Åô„Çã„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„ÅÆÁêÜËß£„ÅåÊ±Ç„ÇÅ„Çâ„Çå„Çã„Åã„Çâ„Åß„Åô„ÄÇ&lt;/p>
&lt;p>Êú¨Á†îÁ©∂„Åß„ÅØ„ÄÅËä∏Ë°ì„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆ„Åü„ÇÅ„ÅÆÊñ∞„Åü„Å™„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÊßãÁØâ„Å´Âêë„Åë„ÅüÂàù„ÅÆË©¶„Åø„Å®„Åó„Å¶„ÄÅAQUA (Art QUestion Answering) „Å®„ÅÑ„ÅÜ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇ„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆË≥™ÂïèÂøúÁ≠îÔºàQAÔºâ„Éö„Ç¢„ÅØ„ÄÅÊó¢Â≠ò„ÅÆÁæéË°ìÁêÜËß£„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´Âê´„Åæ„Çå„ÇãÁµµÁîª„Å®„Ç≥„É°„É≥„Éà„Å´Âü∫„Å•„Åç„ÄÅÊúÄÂÖàÁ´Ø„ÅÆË≥™ÂïèÁîüÊàêÊäÄË°ì„ÇíÁî®„ÅÑ„Å¶Ëá™ÂãïÁîüÊàê„Åï„Çå„Åæ„Åô„ÄÇÁîüÊàê„Åï„Çå„ÅüQA„Éö„Ç¢„ÅØ„ÄÅÊñáÊ≥ï„ÅÆÊ≠£Á¢∫„Åï„ÄÅË≥™Âïè„Å∏„ÅÆÂõûÁ≠îÂèØËÉΩÊÄß„ÄÅ„Åù„Åó„Å¶ÁîüÊàê„Åï„Çå„ÅüÂõûÁ≠î„ÅÆÊ≠£„Åó„Åï„ÇíÂü∫Ê∫ñ„Å®„Åó„Å¶„ÄÅ„ÇØ„É©„Ç¶„Éâ„ÇΩ„Éº„Ç∑„É≥„Ç∞„Å´„Çà„Å£„Å¶„ÇØ„É¨„É≥„Ç∏„É≥„Ç∞„Åï„Çå„Å¶„Åä„Çä„ÄÅÈ´òÂìÅË≥™„Å™„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÊú¨„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØË¶ñË¶öÁöÑÔºàÁµµÁîª„Å´Âü∫„Å•„ÅèÔºâË≥™Âïè„Å®Áü•Ë≠òÁöÑÔºà„Ç≥„É°„É≥„Éà„Å´Âü∫„Å•„ÅèÔºâË≥™Âïè„ÅÆ‰∏°Êñπ„ÇíÂê´„Çì„Åß„ÅÑ„Åæ„Åô„ÄÇ&lt;/p>
&lt;p>„Åï„Çâ„Å´„ÄÅË¶ñË¶öÁöÑË≥™Âïè„Å®Áü•Ë≠òÁöÑË≥™Âïè„Çí„Åù„Çå„Åû„ÇåÁã¨Á´ã„Å´Âá¶ÁêÜ„Åô„Çã„Éô„Éº„Çπ„É©„Ç§„É≥„É¢„Éá„É´„ÇÇÊèêÊ°à„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇÊú¨Á†îÁ©∂„Åß„ÅØ„ÄÅ„Åì„ÅÆ„Éô„Éº„Çπ„É©„Ç§„É≥„É¢„Éá„É´„ÇíÁîªÂÉè„Å´Èñ¢„Åô„ÇãË≥™ÂïèÂøúÁ≠îÂàÜÈáé„ÅÆÊúÄÂÖàÁ´Ø„É¢„Éá„É´„Å®ÊØîËºÉ„Åó„ÄÅËä∏Ë°ìÂàÜÈáé„Å´„Åä„Åë„ÇãË≥™ÂïèÂøúÁ≠î„ÅÆË™≤È°å„ÇÑ‰ªäÂæå„ÅÆÂèØËÉΩÊÄß„Å´„Å§„ÅÑ„Å¶ÂåÖÊã¨ÁöÑ„Å´Ê§úË®é„Åó„Åæ„Åó„Åü„ÄÇ&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/I78SoOkH3dM?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div></description></item><item><title>Automatic evaluation of atlantoaxial subluxation in rheumatoid arthritis by a deep learning model</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/okita-2023-atlantoaxial/</link><pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/okita-2023-atlantoaxial/</guid><description/></item><item><title>Enhancing Fake News Detection in Social Media via Label Propagation on Cross-Modal Tweet Graph</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/zhao-2023-fakenews/</link><pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/zhao-2023-fakenews/</guid><description/></item><item><title>ACT2G: Attention-based Contrastive Learning for Text-to-Gesture Generation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2023-actg/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2023-actg/</guid><description/></item><item><title>Learning bottleneck concepts in image classification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2023-learning/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2023-learning/</guid><description/></item><item><title>Model-agnostic gender debiased image captioning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2023-model/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2023-model/</guid><description/></item><item><title>Multi-modal humor segment prediction in video</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2023-multi/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2023-multi/</guid><description/></item><item><title>Not only generative art: Stable diffusion for content-style disentanglement in art analysis</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2023-notonly/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2023-notonly/</guid><description/></item><item><title>Toward verifiable and reproducible human evaluation for text-to-image generation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2023-toward/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2023-toward/</guid><description/></item><item><title>Uncurated image-text datasets: Shedding light on demographic bias</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2023-uncurated/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2023-uncurated/</guid><description/></item><item><title>Real-time estimation of the remaining surgery duration for cataract surgery using deep convolutional neural networks and long short-term memory</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2023-realtime/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2023-realtime/</guid><description/></item><item><title>Improving facade parsing with vision transformers and line integration</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2024-facade/</link><pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2024-facade/</guid><description/></item><item><title>Explainability matters in medical applications</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/scaiosaka-2023/</link><pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/scaiosaka-2023/</guid><description/></item><item><title>Development of a vertex finding algorithm using recurrent neural network</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/goto-2023-development/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/goto-2023-development/</guid><description/></item><item><title>Inference Time Evidences of Adversarial Attacks for Forensic on Transformers</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/lemarchant-2023-inference/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/lemarchant-2023-inference/</guid><description/></item><item><title>Toward better communication between humans and AI: What do neural networks see?</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/iitosaka-2023/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/iitosaka-2023/</guid><description/></item><item><title>Contrastive Losses Are Natural Criteria for Unsupervised Video Summarization</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2023-contrastive/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2023-contrastive/</guid><description/></item><item><title>Emotional Intensity Estimation based on Writer‚Äôs Personality</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/suzuki-2022-emotional/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/suzuki-2022-emotional/</guid><description/></item><item><title>Foundation of AI</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/isba-2022/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/isba-2022/</guid><description/></item><item><title>What do models see? Bias in neural networks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/sjtuou-2022/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/sjtuou-2022/</guid><description/></item><item><title>Deep Gesture Generation for Social Robots Using Type-Specific Libraries</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2022-deep/</link><pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2022-deep/</guid><description/></item><item><title>Corpus Construction for Historical Newspapers: A Case Study on Public Meeting Corpus Construction Using OCR Error Correction</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2022-corpus/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2022-corpus/</guid><description/></item><item><title>Depthwise spatio-temporal STFT convolutional neural networks for human action recognition</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kumawat-2021-stft/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kumawat-2021-stft/</guid><description/></item><item><title>Ê∑±Â±§Â≠¶Áøí„ÅÆÊúÄËøë„ÅÆË©±È°å„Å®ÂåªÁôÇÂàÜÈáé„Å∏„ÅÆÂøúÁî®</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/jos-2022/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/jos-2022/</guid><description/></item><item><title>ÂàÜÈáé„ÇíË∂Ö„Åà„Åü‰∫∫Â∑•Áü•ËÉΩÁ†îÁ©∂„Å®ÊúÄÊñ∞„ÅÆË©±È°å„Å´„Å§„ÅÑ„Å¶</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/isco-2022/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/isco-2022/</guid><description/></item><item><title>Match them up: Visually explainable few-shot image classification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2022-match/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2022-match/</guid><description/></item><item><title>Multi-label disengagement and behavior prediction in online learning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2022-multi/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2022-multi/</guid><description/></item><item><title>A Japanese Dataset for Subjective and Objective Sentiment Polarity Classification in Micro Blog Domain</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/suzuki-2022-japanese/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/suzuki-2022-japanese/</guid><description/></item><item><title>AxIoU: An Axiomatically Justified Measure for Video Moment Retrieval</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/togashi-2022-cvpr/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/togashi-2022-cvpr/</guid><description/></item><item><title>Gender and racial bias in visual question answering datasets</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2022-facct/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2022-facct/</guid><description/></item><item><title>Optimal Correction Cost for Object Detection Evaluation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2022-cvpr/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2022-cvpr/</guid><description/></item><item><title>Quantifying Societal Bias Amplification in Image Captioning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2022-cvpr/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2022-cvpr/</guid><description/></item><item><title>Tone Classification for Political Advertising Video using Multimodal Cues</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/vo-2022-tone/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/vo-2022-tone/</guid><description/></item><item><title>Information Extraction from Public Meeting Articles</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/virgo-2022-sncs/</link><pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/virgo-2022-sncs/</guid><description/></item><item><title>Recent Machine Learning Techniques and Exploration of New Physics</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/plb-2022/</link><pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/plb-2022/</guid><description/></item><item><title>Anonymous identity sampling and reusable synthesis for sensitive face camouflage</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kuang-2022-privacy/</link><pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kuang-2022-privacy/</guid><description/></item><item><title>Integration of gesture generation system using gesture library with DIY robot design kit</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2022/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2022/</guid><description/></item><item><title>The semantic typology of visually grounded paraphrases</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2021-semantic/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2021-semantic/</guid><description/></item><item><title>Explain me the painting: Multi-topic knowledgeable art description generation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/bai-2021-explain/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/bai-2021-explain/</guid><description/></item><item><title>GCNBoost: Artwork Classification by Label Propagation Through a Knowledge Graph</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/vaigh-202-gcnboost/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/vaigh-202-gcnboost/</guid><description/></item><item><title>Image Retrieval by Hierarchy-aware Deep Hashing Based on Multi-task Learning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-image/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-image/</guid><description/></item><item><title>SCOUTER: Slot attention-based classifier for explainable image recognition</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2021-scouter/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2021-scouter/</guid><description/></item><item><title>Transferring domain-agnostic knowledge in video question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2021-transferring/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2021-transferring/</guid><description/></item><item><title>Built year prediction from Buddha face with heterogeneous labels</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/qian-2021-built/</link><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/qian-2021-built/</guid><description/></item><item><title>Visual question answering with textual representations for images</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2021-visual/</link><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2021-visual/</guid><description/></item><item><title>Learners' efficiency prediction using facial behavior analysis</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2021-learners/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2021-learners/</guid><description/></item><item><title>Museum Experience into a Souvenir: Generating Memorable Postcards from Guide Device Behavior Log</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/shoji-2021/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/shoji-2021/</guid><description/></item><item><title>PoseRN: A 2D pose refinement network for bias-free multi-view 3D human pose estimation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2021-posern/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2021-posern/</guid><description/></item><item><title>Attending self-attention: A case study of visually grounded supervision in vision-and-language transformers</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/samaran-2021-attending/</link><pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/samaran-2021-attending/</guid><description/></item><item><title>Ê©üÊ¢∞„ÅØ‰∏ñÁïå„Çí„Å©„ÅÜË¶ã„Å¶„ÅÑ„Çã„ÅÆ„ÅãÔºü</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/asada-2021/</link><pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/asada-2021/</guid><description/></item><item><title>A comparative study of language Transformers for video question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2021-bert/</link><pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2021-bert/</guid><description/></item><item><title>MTUNet: Few-shot image classification with visual explanations</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-mtunet/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-mtunet/</guid><description/></item><item><title>WRIME: A new dataset for emotional intensity estimation with subjective and objective annotations</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kajiwara-2021-wrime/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kajiwara-2021-wrime/</guid><description/></item><item><title>Noisy-LSTM: Improving temporal awareness for video semantic segmentation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-noisy/</link><pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-noisy/</guid><description/></item><item><title>Generation and detection of media clones</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2021-generation/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2021-generation/</guid><description/></item><item><title>Preventing fake information generation against media clone attacks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2021-preventing/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2021-preventing/</guid><description/></item><item><title>The laughing machine: Predicting humor in video</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kayatani-2021-laughing/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kayatani-2021-laughing/</guid><description/></item><item><title>ContextNet: Representation and exploration for painting classification and retrieval in context</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-contextnet/</link><pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-contextnet/</guid><description/></item><item><title>Cross-lingual visual grounding</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/dong-2020-cross/</link><pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/dong-2020-cross/</guid><description/></item><item><title>IDSOU at WNUT-2020 Task 2: Identification of informative COVID-19 English tweets</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ohashi-2020-idsou/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ohashi-2020-idsou/</guid><description/></item><item><title>Improving topic modeling through homophily for legal documents</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ashihara-2020-improving/</link><pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ashihara-2020-improving/</guid><description/></item><item><title>Uncovering hidden challenges in query-based video moment retrieval</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2020-uncovering/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2020-uncovering/</guid><description/></item><item><title>Visually grounded paraphrase identification via gating and phrase localization</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2020-visually/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2020-visually/</guid><description/></item><item><title>A dataset and baselines for visual question answering on art</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-dataset/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-dataset/</guid><description/></item><item><title>Demographic Influences on Contemporary Art with Unsupervised Style Embeddings</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/huckle-2020/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/huckle-2020/</guid><description/></item><item><title>Knowledge-based video question answering with unsupervised scene descriptions</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-knowledgea/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-knowledgea/</guid><description/></item><item><title>Privacy sensitive large-margin model for face de-identification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/guo-2020-privacy/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/guo-2020-privacy/</guid><description/></item><item><title>Joint learning of vessel segmentation and artery/vein classification with post-processing</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2020-joint/</link><pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2020-joint/</guid><description/></item><item><title>Knowledge-Based Visual Question Answering in Videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-women/</link><pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-women/</guid><description/></item><item><title>Yoga-82: A new dataset for fine-grained classification of human poses</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2020-yoga/</link><pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2020-yoga/</guid><description/></item><item><title>Constructing a public meeting corpus</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2020-constructing/</link><pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2020-constructing/</guid><description/></item><item><title>Warmer environments increase implicit mental workload even if learning efficiency is enhanced</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kimura-2020-warmer/</link><pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kimura-2020-warmer/</guid><description/></item><item><title>BERT representations for video question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2020-bert/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2020-bert/</guid><description/></item><item><title>IterNet: Retinal image segmentation utilizing structural redundancy in vessel networks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2020-iternet/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2020-iternet/</guid><description/></item><item><title>Toward predicting learners' efficiency for adaptive e-learning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2020-toward/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2020-toward/</guid><description/></item><item><title>Video analytics in blended learning: Insights from learner-video interaction patterns</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/alizadeh-2020-video/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/alizadeh-2020-video/</guid><description/></item><item><title>KnowIT VQA: Answering knowledge-based questions about videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/gacria-2020-knowit/</link><pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/gacria-2020-knowit/</guid><description/></item><item><title>3D image reconstruction from multi-focus microscopic images</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yamaguchi-20203-d/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yamaguchi-20203-d/</guid><description/></item><item><title>Speech-driven face reenactment for a video sequence</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2020-speech/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2020-speech/</guid><description/></item><item><title>Public Meeting Corpus Construction and Content Delivery</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2019-public/</link><pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2019-public/</guid><description/></item><item><title>Human shape reconstruction with loose clothes from partially observed data by pose specific deformation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2019-human/</link><pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2019-human/</guid><description/></item><item><title>Legal information as a complex network: Improving topic modeling through homophily</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ashihara-2019-legal/</link><pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ashihara-2019-legal/</guid><description/></item><item><title>Adaptive gating mechanism for identifying visually grounded paraphrases</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-adaptive/</link><pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-adaptive/</guid><description/></item><item><title>BUDA.ART: A multimodal content-based analysis and retrieval system for Buddha statues</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/renoust-2019-budaart/</link><pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/renoust-2019-budaart/</guid><description/></item><item><title>Historical and modern features for Buddha statue classification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2019-historical/</link><pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2019-historical/</guid><description/></item><item><title>Using external knowledge in the deep learning framework</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-seminarkek/</link><pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-seminarkek/</guid><description/></item><item><title>Facial expression recognition with skip-connection to leverage low-level features</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2019-facial/</link><pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2019-facial/</guid><description/></item><item><title>Buddha statues archive retrieval system</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2019-miru/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2019-miru/</guid><description/></item><item><title>Collecting relation-aware video captions</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-miru/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-miru/</guid><description/></item><item><title>GAN„ÇíÁî®„ÅÑ„ÅüÈ°î„ÅÆRGBÁîªÂÉè„Å®Â••Ë°åÁîªÂÉè„ÅÆÂêåÊôÇÁîüÊàê</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kobayashi-2019/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kobayashi-2019/</guid><description/></item><item><title>Video meets knowledge in visual question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-miru/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-miru/</guid><description/></item><item><title>Video question answering with BERT</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2019-miru/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2019-miru/</guid><description/></item><item><title>AI/Ê©üÊ¢∞Â≠¶Áøí/Ê∑±Â±§Â≠¶ÁøíÂÖ•ÈñÄ</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/pyis-2019-seminaracc/</link><pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/pyis-2019-seminaracc/</guid><description/></item><item><title>Context-aware embeddings for automatic art analysis</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-context/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-context/</guid><description/></item><item><title>Rethinking the evaluation of video summaries</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-rethinking/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-rethinking/</guid><description/></item><item><title>„Ç≥„É°„Éá„Ç£„Éâ„É©„Éû„Å´„Åä„Åë„ÇãÂ≠óÂπï„Å®Ë°®ÊÉÖ„ÇíÁî®„ÅÑ„ÅüÁ¨ë„ÅÑ‰∫àÊ∏¨</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kayatani-2019/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kayatani-2019/</guid><description/></item><item><title>Multimodal learning analytics: Society 5.0 project in Japan</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/shirai-2019-multimodal/</link><pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/shirai-2019-multimodal/</guid><description/></item><item><title>Problems dealt with machine learning/deep learning and its applications to nuclear physics</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-nakano/</link><pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-nakano/</guid><description/></item><item><title>Talking Head Generation with Deep Phoneme and Viseme Representation and Generative Adversarial Networks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yasui-2019-talking/</link><pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yasui-2019-talking/</guid><description/></item><item><title>ÊÉÖÂ†±Â≠¶„Å®Áâ©ÁêÜÂ≠¶„ÅÆ„ÇØ„É≠„Çπ„Ç™„Éº„Éê„Éº</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-cross/</link><pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-cross/</guid><description/></item><item><title>Faces in an Archive of Buddhism Pictures</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/renoust-2019-buddha/</link><pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/renoust-2019-buddha/</guid><description/></item><item><title>Â§öÈáçÁÑ¶ÁÇπÈ°ïÂæÆÈè°ÁîªÂÉèÂàó„Åã„Çâ„ÅÆÁ¥∞ËÉû„ÅÆ3Ê¨°ÂÖÉÂΩ¢Áä∂Âæ©ÂÖÉ</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yamaguchi-2019/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yamaguchi-2019/</guid><description/></item><item><title>Finding important people in a video using deep neural networks with conditional random fields</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-finding/</link><pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-finding/</guid><description/></item><item><title>Exploration and Mining of 50,000 Buddha Pictures</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2018-miru/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2018-miru/</guid><description/></item><item><title>iParaphrasing: Extracting visually grounded paraphrases via an image</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2018-ipara/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2018-ipara/</guid><description/></item><item><title>Iterative applications of image completion with CNN-based failure detection</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2018-iterative/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2018-iterative/</guid><description/></item><item><title>OpenCV„Å®Python„Å´„Çà„ÇãÊ©üÊ¢∞Â≠¶Áøí„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/michael-2018/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/michael-2018/</guid><description/></item><item><title>Phrase localization-based visually grounded paraphrase identification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-miruphrase/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-miruphrase/</guid><description/></item><item><title>Representing a partially observed non-rigid 3D human using eigen-texture and eigen-deformation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kiura-2018-representing/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kiura-2018-representing/</guid><description/></item><item><title>Summarization of user-generated sports video by using deep action recognition features</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tejerodepablos-2018-summarization/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tejerodepablos-2018-summarization/</guid><description/></item><item><title>Synthesis of human shape in loose cloth using eigen-deformation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2019-miru/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2019-miru/</guid><description/></item><item><title>Linking videos and languages: Representations and their applications</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-cvim/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-cvim/</guid><description/></item><item><title>Extracting Paraphrases Grounded by an Image</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2018-extracting/</link><pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2018-extracting/</guid><description/></item><item><title>Finding Video Parts with Natural Language</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-findinga/</link><pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-findinga/</guid><description/></item><item><title>Ëá™Áî±Ë¶ñÁÇπÁîªÂÉèÁîüÊàê„ÅÆ„Åü„ÇÅ„ÅÆEigen-TextureÊ≥ï„Å´„Åä„Åë„Çã‰øÇÊï∞„ÅÆÂõûÂ∏∞</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2017-eigen/</link><pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2017-eigen/</guid><description/></item><item><title>Augmented reality marker hiding with texture deformation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kawai-2017-augmented/</link><pubDate>Sun, 01 Oct 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kawai-2017-augmented/</guid><description/></item><item><title>Video question answering to find a desired video segment</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2017-demo/</link><pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2017-demo/</guid><description/></item><item><title>Novel view synthesis with light-weight view-dependent texture mapping for a stereoscopic HMD</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/rongsirigul-2017-novel/</link><pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/rongsirigul-2017-novel/</guid><description/></item><item><title>ÁîªÂÉèÂá¶ÁêÜ„ÉªÊ©üÊ¢∞Â≠¶Áøí„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞OpenCV 3ÂØæÂøú</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/opencv-2017/</link><pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/opencv-2017/</guid><description/></item><item><title>Video summarization using textual descriptions for authoring video blogs</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2017-video/</link><pubDate>Mon, 01 May 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2017-video/</guid><description/></item><item><title>DNN„ÇíÁî®„ÅÑ„Åü„Ç´„É°„É©„ÅÆ6Ëá™Áî±Â∫¶Áõ∏ÂØæÈÅãÂãïÊé®ÂÆö</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hashioka-20178-dnn/</link><pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hashioka-20178-dnn/</guid><description/></item><item><title>ÊúÄËøë„ÅÆÈáçË¶Å„Å™Ë´ñÊñá„ÅÆÁ¥π‰ªã -- „ÉÜ„Ç≠„Çπ„Éà„Å®„ÅÆÂØæÂøú‰ªò„Åë„Å´„Çà„ÇãÊò†ÂÉè„ÅÆÁêÜËß£„Å´Èñ¢ÈÄ£„Åó„Å¶</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/stair-2017/</link><pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/stair-2017/</guid><description/></item><item><title>Increasing pose comprehension through augmented reality reenactment</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2017-increasing/</link><pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2017-increasing/</guid><description/></item><item><title>ReMagicMirror: Action learning using human reenactment with the mirror metaphor</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2017-remagicmirroir/</link><pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2017-remagicmirroir/</guid><description/></item><item><title>Flexible human action recognition in depth video sequences using masked joint trajectories</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tejero-2016-flexible/</link><pubDate>Thu, 01 Dec 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tejero-2016-flexible/</guid><description/></item><item><title>Ê∑±Â±§Â≠¶Áøí„ÇíÂà©Áî®„Åó„ÅüÊò†ÂÉèË¶ÅÁ¥Ñ„Å∏„ÅÆÂèñ„ÇäÁµÑ„Åø</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/stair-2016/</link><pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/stair-2016/</guid><description/></item><item><title>Video summarization using deep semantic features</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2016-video/</link><pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2016-video/</guid><description/></item><item><title>Learning joint representations of videos and sentences with web image search</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2016-learning/</link><pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2016-learning/</guid><description/></item><item><title>Human action recognition-based video summarization for RGB-D personal sports video</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tejerodepablo-2016-human/</link><pubDate>Fri, 01 Jul 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tejerodepablo-2016-human/</guid><description/></item><item><title>Joint representation of video and text using deep neural networks with help of web images</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/msra-2016/</link><pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/msra-2016/</guid><description/></item><item><title>Privacy protection for social video via background estimation and CRF-based videographer's intention modeling</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2016-privacy/</link><pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2016-privacy/</guid><description/></item><item><title>Novel View Synthesis Based on View-dependent Texture Mapping with Geometry-aware Color Continuity</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/katagiri-2016-novel/</link><pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/katagiri-2016-novel/</guid><description/></item><item><title>3D shape template generation from RGB-D images capturing a moving and deforming object</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-20163-d/</link><pubDate>Mon, 01 Feb 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-20163-d/</guid><description/></item><item><title>Áï≥„ÅøËæº„Åø„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÇíÁî®„ÅÑ„Åü‰øÆÂæ©Â§±ÊïóÈ†òÂüü„ÅÆËá™ÂãïÊ§úÂá∫„Å´„Çà„ÇãÁîªÂÉè‰øÆÂæ©„ÅÆÂèçÂæ©ÁöÑÈÅ©Áî®</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2016-dnn/</link><pubDate>Mon, 01 Feb 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2016-dnn/</guid><description/></item><item><title>Acceleration of View-dependent Texture Mapping-based Novel View Synthesis for stereoscopic HMD</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/rongsirigul-2016/</link><pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/rongsirigul-2016/</guid><description/></item><item><title>Evaluating protection capability for visual privacy information</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2016-evaluating/</link><pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2016-evaluating/</guid><description/></item><item><title>ÁîªÂÉè‰øÆÂæ©„Å´„Åä„Åë„ÇãÁï≥„ÅøËæº„Åø„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÇíÁî®„ÅÑ„Åü‰øÆÂæ©Â§±ÊïóÈ†òÂüü„ÅÆËá™ÂãïÊ§úÂá∫</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2015-ite/</link><pubDate>Tue, 01 Dec 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2015-ite/</guid><description/></item><item><title>2035Âπ¥„ÅÆ„Éû„É´„ÉÅ„É°„Éá„Ç£„Ç¢„ÅÆÂßø„Çí‰∫àÊÉ≥--ICME 2015 ‰ºöË≠∞„É¨„Éù„Éº„Éà</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/icme-2015-report/</link><pubDate>Thu, 01 Oct 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/icme-2015-report/</guid><description/></item><item><title>OpenCV 3 „Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„Éñ„ÉÉ„ÇØ</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/opencv-2015/</link><pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/opencv-2015/</guid><description/></item><item><title>Âçò‰∏Ä„ÅÆRGB-D„Ç´„É°„É©„ÇíÁî®„ÅÑ„ÅüÈùûÂâõ‰ΩìÁâ©‰Ωì„ÅÆ3Ê¨°ÂÖÉÂΩ¢Áä∂Âæ©ÂÖÉ</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2015/</link><pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2015/</guid><description/></item><item><title>Facial expression preserving privacy protection using image melding</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2015-facial/</link><pubDate>Mon, 01 Jun 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2015-facial/</guid><description/></item><item><title>Textual description-based video summarization for video blogs</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2015-textual/</link><pubDate>Mon, 01 Jun 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2015-textual/</guid><description/></item><item><title>„ÉÜ„ÇØ„Çπ„ÉÅ„É£„ÅÆÈÄ£Á∂öÊÄß„ÇíËÄÉÊÖÆ„Åó„ÅüË¶ñÁÇπ‰æùÂ≠ò„ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éû„ÉÉ„Éî„É≥„Ç∞„Å´„Çà„ÇãËá™Áî±Ë¶ñÁÇπÁîªÂÉèÁîüÊàê</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/katagiri-2015/</link><pubDate>Sun, 01 Mar 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/katagiri-2015/</guid><description/></item><item><title>ÁâπÂæ¥ÁÇπ„ÅÆÊòéÁ§∫ÁöÑ„Å™ÂØæÂøú‰ªò„Åë„Çí‰º¥„Çè„Å™„ÅÑ„Ç´„É°„É©‰ΩçÁΩÆÂßøÂã¢Êé®ÂÆö</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2015/</link><pubDate>Sun, 01 Mar 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2015/</guid><description/></item><item><title>AR image generation using view-dependent geometry modification and texture mapping</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2015-ar/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2015-ar/</guid><description/></item><item><title>Protection and utilization of privacy information via sensing</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2015-protection/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2015-protection/</guid><description/></item><item><title>RGB-D„Ç´„É°„É©„ÇíÁî®„ÅÑ„ÅüÈùûÂâõ‰ΩìÁâ©‰Ωì„ÅÆÂãï„ÅçÂæ©ÂÖÉ„ÅÆ„Åü„ÇÅ„ÅÆRGBÁîªÂÉè‰∏ä„ÅÆÂØæÂøúÁÇπ„Å´Âü∫„Å•„Åè3Ê¨°ÂÖÉ„ÉÜ„É≥„Éó„É¨„Éº„ÉàÁîüÊàê</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2015-rgbd/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2015-rgbd/</guid><description/></item><item><title>„ÉÜ„Ç≠„Çπ„Éà„Å®Êò†ÂÉè„ÅÆÈ°û‰ººÂ∫¶„ÇíÁî®„ÅÑ„ÅüÊò†ÂÉèË¶ÅÁ¥Ñ</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2015-text/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2015-text/</guid><description/></item><item><title>ÁâπÂæ¥ÁÇπ„ÅÆÊòéÁ§∫ÁöÑ„Å™ÂØæÂøú‰ªò„Åë„Çí‰º¥„Çè„Å™„ÅÑ„Ç´„É°„É©‰ΩçÁΩÆÂßøÂã¢Êé®ÂÆö</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2015-features/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2015-features/</guid><description/></item><item><title>RGB-D„Ç´„É°„É©„ÇíÁî®„ÅÑ„ÅüÈùûÂâõ‰ΩìÁâ©‰Ωì„ÅÆÂãï„ÅçÂæ©ÂÖÉ„ÅÆ„Åü„ÇÅ„ÅÆ3Ê¨°ÂÖÉ„ÉÜ„É≥„Éó„É¨„Éº„ÉàÂΩ¢Áä∂ÁîüÊàê</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2014-rgb/</link><pubDate>Mon, 01 Dec 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2014-rgb/</guid><description/></item><item><title>ÁâπÂæ¥ÁÇπ„ÅÆÈ°û‰ººÂ∫¶Â∞∫Â∫¶„Å´„Çà„ÇãÂØæÂøú‰ªò„Åë„Çí‰º¥„Çè„Å™„ÅÑ„Ç´„É°„É©‰ΩçÁΩÆÂßøÂã¢Êé®ÂÆöÊâãÊ≥ï„ÅÆÊ§úË®é</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2014-ite/</link><pubDate>Mon, 01 Sep 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2014-ite/</guid><description/></item><item><title>Background estimation for a single omnidirectional image sequence captured with a moving camera</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kawai-2014-background/</link><pubDate>Tue, 01 Jul 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kawai-2014-background/</guid><description/></item><item><title>Free-viewpoint AR human-motion reenactment based on a single RGB-D video stream</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2014-free/</link><pubDate>Tue, 01 Jul 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2014-free/</guid><description/></item><item><title>ÁîªÂÉè„ÅÆ„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„Çí‰øùÊåÅ„Åó„ÅüË¶ñË¶öÁöÑ„Å´Ëá™ÁÑ∂„Å™„Éó„É©„Ç§„Éê„Ç∑„Éº‰øùË≠∑Âá¶ÁêÜ</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2014/</link><pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2014/</guid><description/></item><item><title>Ëá™Áî±Ë¶ñÁÇπÁîªÂÉèÁîüÊàê„Å´Âü∫„Å•„ÅèÁßªÂãïÊíÆÂΩ±„Åó„ÅüÂÖ®Êñπ‰ΩçÂãïÁîªÂÉè„Åã„Çâ„ÅÆÂãïÁâ©‰ΩìÈô§Âéª</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/inoue-2014/</link><pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/inoue-2014/</guid><description/></item><item><title>Single RGB-D Video-stream Based Human-motion Reenactment</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/enzo-2014-single/</link><pubDate>Sat, 01 Feb 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/enzo-2014-single/</guid><description/></item><item><title>Augmented reality image generation with virtualized real objects using view-dependent texture and geometry</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2013-augmented/</link><pubDate>Tue, 01 Oct 2013 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2013-augmented/</guid><description/></item><item><title>Inferring what the videographer wanted to capture</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2013-inferring/</link><pubDate>Sun, 01 Sep 2013 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2013-inferring/</guid><description/></item><item><title>Real-time privacy protection system for social videos using intentionally-captured persons detection</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2013-realtime/</link><pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2013-realtime/</guid><description/></item><item><title>Êã°ÂºµÁèæÂÆüÊÑü„ÅÆ„Åü„ÇÅ„ÅÆË¶ñÁÇπ‰æùÂ≠ò„ÉÜ„ÇØ„Çπ„ÉÅ„É£„Éª„Ç∏„Ç™„É°„Éà„É™„Å´Âü∫„Å•„Åè‰ªÆÊÉ≥ÂåñÂÆüÁâ©‰Ωì„ÅÆËº™ÈÉ≠ÂΩ¢Áä∂„ÅÆ‰øÆÂæ©</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uno-2013-ar/</link><pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uno-2013-ar/</guid><description/></item><item><title>Markov random field-based real-time detection of intentionally-captured persons</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2012-markov/</link><pubDate>Sat, 01 Sep 2012 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2012-markov/</guid><description/></item><item><title>È°îÁîªÂÉè„Å´ÂØæ„Åô„Çã„Éó„É©„Ç§„Éê„Ç∑„Éº‰øùË≠∑Âá¶ÁêÜ„ÅÆÊúâÂäπÊÄß„ÅÆÂÆöÈáèÁöÑË©ï‰æ°</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2012-privacy/</link><pubDate>Sun, 01 Jul 2012 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2012-privacy/</guid><description/></item><item><title>Intended human object detection for automatically protecting privacy in mobile video surveillance</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2012-intended/</link><pubDate>Thu, 01 Mar 2012 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2012-intended/</guid><description/></item><item><title>Extracting intentionally captured regions using point trajectories</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-extracting/</link><pubDate>Tue, 01 Nov 2011 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-extracting/</guid><description/></item><item><title>Indoor positioning system using digital audio watermarking</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-indoor/</link><pubDate>Tue, 01 Nov 2011 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-indoor/</guid><description/></item><item><title>Automatic generation of privacy-protected videos using background estimation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-automatic/</link><pubDate>Fri, 01 Jul 2011 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-automatic/</guid><description/></item><item><title>„Ç´„É°„É©„ÅÆÂãï„Åç„Å®Êò†ÂÉèÁâπÂæ¥„Åã„Çâ„ÅÆÊíÆÂΩ±ËÄÖ„ÅåÊÑèÂõ≥„Åó„ÅüÈ†òÂüü„ÅÆÊé®ÂÆö</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2011/</link><pubDate>Fri, 01 Jul 2011 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2011/</guid><description/></item><item><title>Automatically protecting privacy in consumer generated videos using intended human object detector</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2010-automatically/</link><pubDate>Fri, 01 Oct 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2010-automatically/</guid><description/></item><item><title>Discriminating intended human objects in consumer videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2010-discriminating/</link><pubDate>Sun, 01 Aug 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2010-discriminating/</guid><description/></item><item><title>Real-time user position estimation in indoor environments using digital watermarking for audio signals</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2010-realtime/</link><pubDate>Sun, 01 Aug 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2010-realtime/</guid><description/></item><item><title>Detecting intended human objects in human-captured videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2010-detecting/</link><pubDate>Tue, 01 Jun 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2010-detecting/</guid><description/></item><item><title>Digital diorama: Sensing-based real-world visualization</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2010-digital/</link><pubDate>Tue, 01 Jun 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2010-digital/</guid><description/></item><item><title>Êò†ÂÉè‰∏≠„ÅÆÊíÆÂΩ±ËÄÖ„ÅåÊÑèÂõ≥„Åó„Åü‰∫∫Áâ©Ë¢´ÂÜô‰Ωì„ÅÆÊ§úÂá∫</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2010/</link><pubDate>Mon, 01 Mar 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2010/</guid><description/></item><item><title>Èü≥ÈüøÈõªÂ≠êÈÄè„Åã„Åó„ÇíÁî®„ÅÑ„ÅüÂ±ãÂÜÖ„Åß„ÅÆÈå≤Èü≥‰ΩçÁΩÆÊé®ÂÆö</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2010/</link><pubDate>Mon, 01 Mar 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2010/</guid><description/></item><item><title>Êò†ÂÉèÁâπÂæ¥„Å´Âü∫„Å•„ÅèÊíÆÂΩ±ËÄÖ„ÅåÊÑèÂõ≥„Åó„Åü‰∫∫Áâ©Ë¢´ÂÜô‰Ωì„ÅÆÊé®ÂÆö</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2009/</link><pubDate>Sat, 01 Aug 2009 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2009/</guid><description/></item><item><title>Watermarked movie soundtrack finds the position of the camcorder in a theater</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2009-watermarked/</link><pubDate>Sun, 01 Mar 2009 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2009-watermarked/</guid><description/></item><item><title>Èü≥ÈüøÈõªÂ≠êÈÄè„Åã„Åó„ÅÆÊ§úÂá∫Âº∑Â∫¶„ÇíÁî®„ÅÑ„Åü‰ΩçÁΩÆÊé®ÂÆö</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2009/</link><pubDate>Sun, 01 Mar 2009 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2009/</guid><description/></item><item><title>Maximum-likelihood estimation of recording position based on audio watermarking</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2007-maximum/</link><pubDate>Thu, 01 Nov 2007 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2007-maximum/</guid><description/></item><item><title>Determining Recording Location Based on Synchronization Positions of Audio watermarking</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2007-determining/</link><pubDate>Sun, 01 Apr 2007 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2007-determining/</guid><description/></item><item><title>Estimation of recording location using audio watermarking</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2006-estimation/</link><pubDate>Fri, 01 Sep 2006 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2006-estimation/</guid><description/></item></channel></rss>