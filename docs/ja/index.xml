<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>複合知能メディア研究室</title><link>https://im.sanken.osaka-u.ac.jp/ja/</link><atom:link href="https://im.sanken.osaka-u.ac.jp/ja/index.xml" rel="self" type="application/rss+xml"/><description>複合知能メディア研究室</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>ja-jp</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate><image><url>https://im.sanken.osaka-u.ac.jp/media/logo_hu_5496ce6447801688.png</url><title>複合知能メディア研究室</title><link>https://im.sanken.osaka-u.ac.jp/ja/</link></image><item><title>✨ M1、B4が配属されました</title><link>https://im.sanken.osaka-u.ac.jp/ja/post/newcomers2025/</link><pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/post/newcomers2025/</guid><description>&lt;p>外部進学のM1が2名、B4が4名、フロンティアラボの学生さんが1名配属されました。中島研としては第1期生となります。&lt;/p>
&lt;p>研究も遊びも楽しんでください！&lt;/p></description></item><item><title>🔄 複合知能メディア分野はリニューアルします</title><link>https://im.sanken.osaka-u.ac.jp/ja/post/renewal/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/post/renewal/</guid><description>&lt;p>八木教授の退任と中島の着任に伴い、大阪大学産業科学研究所第1研究部門 複合知能メディア分野は2025年4月1日より中島研究室（MIMLab）として活動を始めました。&lt;/p>
&lt;p>八木先生が築いた研究室の基盤を引き継ぎつつ、新しい研究室として研究もそのほかの活動も楽しんでもらいたいと思います。&lt;/p></description></item><item><title>AIのバイアスとその低減</title><link>https://im.sanken.osaka-u.ac.jp/ja/topics/ethical-ai/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/topics/ethical-ai/</guid><description/></item><item><title>🧑‍🎓 中島研究室（MIMLab）への配属を希望する学生さんへ</title><link>https://im.sanken.osaka-u.ac.jp/ja/post/recruit/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/post/recruit/</guid><description>&lt;p>大阪大学産業科学研究所第1研究部門 複合知能メディア研究分野（中島研究室、MIMLab）は、大阪大学大学院情報科学研究科の協力講座として、&lt;a href="https://www.ics.es.osaka-u.ac.jp/" target="_blank" rel="noopener">大阪大学基礎工学部情報科学科計算機科学コース、ソフトウェア科学コース&lt;/a>、及び&lt;a href="https://www.ist.osaka-u.ac.jp/japanese/" target="_blank" rel="noopener">大阪大学情報科学研究科&lt;/a>の学生さんを受け入れています。&lt;/p>
&lt;p>学部生として当研究室への配属を希望される場合は、大阪大学基礎工学部情報科学科からになります（&lt;a href="https://www.ics.es.osaka-u.ac.jp/exam/" target="_blank" rel="noopener">入試情報&lt;/a>）。&lt;/p>
&lt;p>大学院生として配属を希望される場合は、大阪大学情報科学研究からとなります（&lt;a href="https://www.ist.osaka-u.ac.jp/japanese/examinees/" target="_blank" rel="noopener">入試情報&lt;/a>）。博士前期課程、博士後期課程いずれも事前に&lt;a href="https://im.sanken.osaka-u.ac.jp/ja/#access">こちら&lt;/a>のメールアドレス宛にCVと研究提案書をお送りいただけると、スクリーニング、面談の上でさまざまなサポートができると思います（CVと研究提案書はスクリーニングの目的のみで利用いたします）。&lt;/p>
&lt;p>当研究室では、学生生活を楽しく過ごしつつ、研究に興味を持って取り組んでくれる学生さんを歓迎します。トップカンファレンスを目指して研究を進めたいという皆様は、ぜひ当研究室をご検討ください。一方で、特に大学院からの配属希望の場合は、それまでの研究経験を重視してスクリーニングを実施します。&lt;/p>
&lt;p>楽しく研究したい、という学生さんをお待ちしています。&lt;/p></description></item><item><title>説明可能なAI</title><link>https://im.sanken.osaka-u.ac.jp/ja/topics/explainable-ai/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/topics/explainable-ai/</guid><description/></item><item><title>大規模モデルの応用</title><link>https://im.sanken.osaka-u.ac.jp/ja/topics/agent-by-llms/</link><pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/topics/agent-by-llms/</guid><description/></item><item><title>No Annotations for Object Detection in Art through Stable Diffusion</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ramos-2025-nada/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ramos-2025-nada/</guid><description/></item><item><title>PALADIN: Understanding Video Intentions in Political Advertisement Videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/liu-2025-paladin/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/liu-2025-paladin/</guid><description/></item><item><title>Cross-modal Guided Visual Representation Learning for Social Image Retrieval</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/guan-2024-crossmodal/</link><pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/guan-2024-crossmodal/</guid><description/></item><item><title>DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2024-direct/</link><pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2024-direct/</guid><description/></item><item><title>From Descriptive Richness to Bias: Unveiling the Dark Side of Generative Image Caption Enrichment</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-from/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-from/</guid><description/></item><item><title>Learning More May Not Be Better: Knowledge Transferability in Vision-and-Language Tasks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-learning/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-learning/</guid><description/></item><item><title>Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-resampled/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-resampled/</guid><description/></item><item><title>A picture may be worth a hundred words for visual question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-apicture/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2024-apicture/</guid><description/></item><item><title>Is cardiovascular risk profiling from UK Biobank retinal images using explicit deep learning estimates of traditional risk factors equivalent to actual risk measurements? A prospective cohort study design</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/qian-2024-cardiovascular/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/qian-2024-cardiovascular/</guid><description/></item><item><title>MicroEmo: Time-Sensitive Multimodal Emotion Recognition with Subtle Clue Dynamics in Video Dialogues</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/zhang-2024-microemo/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/zhang-2024-microemo/</guid><description/></item><item><title>Stable Diffusion Exposed: Gender Bias from Prompt to Image</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2024-exposed/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2024-exposed/</guid><description/></item><item><title>Unleashing the Power of Contrastive Learning for Zero-Shot Video Summarization</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2024-videosummary/</link><pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2024-videosummary/</guid><description/></item><item><title>Situating the social issues of image generation models in the model life cycle: a sociotechnical approach</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/katirai-2024-socialissues/</link><pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/katirai-2024-socialissues/</guid><description/></item><item><title>Auditing Image-based NSFW Classifiers for Content Filtering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/leu-2024-auditingnsfw/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/leu-2024-auditingnsfw/</guid><description/></item><item><title>Exploring Emotional Stimuli Detection in Artworks: A Benchmark Dataset and Baselines Evaluation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-emotional/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-emotional/</guid><description/></item><item><title>GOYA: Leveraging Generative Art for Content-Style Disentanglement</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2024-goya/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2024-goya/</guid><description/></item><item><title>Would Deep Generative Models Amplify Bias in Future Models?</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-future/</link><pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-future/</guid><description/></item><item><title>Reproducibility Companion Paper: Stable Diffusion for Content-Style Disentanglement in Art Analysis</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2025-reproducibility/</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2025-reproducibility/</guid><description/></item><item><title>Retrieving Emotional Stimuli in Artworks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-emotion/</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chen-2024-emotion/</guid><description/></item><item><title>Instruct me more! Random prompting for visual in-context learning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/zhang-2024-instruct/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/zhang-2024-instruct/</guid><description/></item><item><title>Revisiting pixel-level contrastive pre-training on scene images</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2024-revisiting/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2024-revisiting/</guid><description/></item><item><title>Societal Bias in Vision-and-Language Datasets and Models</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2024-bias/</link><pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2024-bias/</guid><description/></item><item><title>Vision and Language</title><link>https://im.sanken.osaka-u.ac.jp/ja/topics/vision-and-language/</link><pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/topics/vision-and-language/</guid><description>&lt;p>深層学習の登場以来、Vision and Language、つまり視覚と自然言語を扱う研究は、コンピュータビジョン分野や自然言語処理分野における中心的なトピックの一つとなりました。画像や映像の意味を理解することと、それらを自然言語で表現できることは、強い関連があると考えられます。以下では、当研究室での取り組みの一例を紹介します（一部、ChatGPTによる日本語訳です）。&lt;/p>
&lt;h2 id="explain-me-the-painting-絵画の説明文生成">Explain Me the Painting: 絵画の説明文生成&lt;/h2>
&lt;p>絵画を見て、「この作品にはどんな物語があるのだろう？」と思ったことはありますか？本研究では、芸術作品に対する理解を深め、芸術を人々により身近なものとするために、美術絵画に対する説明文を生成する枠組みを提案します。現在の人工知能技術をもってしても、芸術作品に対して情報量の多い説明を生成することは困難です。というのも、そのためには作品のスタイル、内容、構図など複数の側面を理解して記述し、さらに画家やその影響、また歴史的背景に関する知識も付け加える必要があるからです。&lt;/p>
&lt;p>本研究ではマルチトピックかつ知識に基づいたフレームワークを導入します。このフレームワークでは、生成される文章を3つの芸術的トピックに沿って構成し、さらに外部知識を活用して各説明を強化します。本フレームワークは、定量的および定性的な評価、さらに人間による比較評価において、トピックの多様性および情報の正確性の両面で優れた結果を示しました。&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/lRtyhIHyZFw?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>詳細とコードは&lt;a href="https://sites.google.com/view/art-description-generation" target="_blank" rel="noopener">こちらのページ&lt;/a>からご確認ください。&lt;/p>
&lt;h2 id="部分映像検索の性能評価における表層的相関の問題">部分映像検索の性能評価における表層的相関の問題&lt;/h2>
&lt;p>自然言語クエリによる部分映像検索とは、映像の中からクエリに対応する部分映像を特定・抽出するタスクです。
自然言語と映像の両方の意味を理解する必要があるため、非常に難易度の高いタスクだと言えます。他の多くのコンピュータビジョンや機械学習の分野の様々なタスクと同様に、部分映像検索の進展はベンチマークデータセットに支えられており、それゆえにデータセットの質がこのタスクに取り組む研究コミュニティ全体に大きな影響を与えます。&lt;/p>
&lt;p>部分映像検索タスクにおいては（他のタスクと同様に）様々なモデルが提案され、ベンチマークのランキングがどんどん更新されてきました。本研究では、このベンチマークの結果が、実際のモデルの性能をどれだけ正確に反映しているかを実験的に示しています。もしベンチマークがモデルを正しく評価できていないとすれば、大きな問題です。実験結果からは、広く使われるベンチマークデータセットには大きなバイアスが内包されていること、さらに当時の最新モデルはこのバイアスを利用していることが疑われる挙動が明らかになりました。&lt;/p>
&lt;p>加えて、本研究では新たなサニティチェック（妥当性確認）実験や、結果を視覚的に理解するためのアプローチも提案するとともに、部分映像検索の評価方法を改善するための方向性についても提案します。&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/4xYcR42atws?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div>
&lt;p>詳細とコードは&lt;a href="https://mayu-ot.github.io/hidden-challenges-MR/" target="_blank" rel="noopener">こちらのページ&lt;/a>からご確認ください。&lt;/p>
&lt;h2 id="絵画に関する質問応答のためのデータセット">絵画に関する質問応答のためのデータセット&lt;/h2>
&lt;p>芸術作品（絵画）に関する質問に答えることは人工知能にとって困難な課題です。なぜなら、多くの場合、絵画について何か質問するときは、そこに描かれた視覚的な情報だけでなく、美術史の学習を通じて得られるその絵画に関するコンテキストの理解が求められるからです。&lt;/p>
&lt;p>本研究では、芸術に関する質問応答のための新たなデータセットの構築に向けた初の試みとして、AQUA (Art QUestion Answering) というデータセットを紹介します。このデータセットの質問応答（QA）ペアは、既存の美術理解データセットに含まれる絵画とコメントに基づき、最先端の質問生成技術を用いて自動生成されます。生成されたQAペアは、文法の正確さ、質問への回答可能性、そして生成された回答の正しさを基準として、クラウドソーシングによってクレンジングされており、高品質なデータセットとなっています。本データセットは視覚的（絵画に基づく）質問と知識的（コメントに基づく）質問の両方を含んでいます。&lt;/p>
&lt;p>さらに、視覚的質問と知識的質問をそれぞれ独立に処理するベースラインモデルも提案しています。本研究では、このベースラインモデルを画像に関する質問応答分野の最先端モデルと比較し、芸術分野における質問応答の課題や今後の可能性について包括的に検討しました。&lt;/p>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/I78SoOkH3dM?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video">&lt;/iframe>
&lt;/div></description></item><item><title>Automatic evaluation of atlantoaxial subluxation in rheumatoid arthritis by a deep learning model</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/okita-2023-atlantoaxial/</link><pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/okita-2023-atlantoaxial/</guid><description/></item><item><title>Enhancing Fake News Detection in Social Media via Label Propagation on Cross-Modal Tweet Graph</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/zhao-2023-fakenews/</link><pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/zhao-2023-fakenews/</guid><description/></item><item><title>ACT2G: Attention-based Contrastive Learning for Text-to-Gesture Generation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2023-actg/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2023-actg/</guid><description/></item><item><title>Learning bottleneck concepts in image classification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2023-learning/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2023-learning/</guid><description/></item><item><title>Model-agnostic gender debiased image captioning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2023-model/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2023-model/</guid><description/></item><item><title>Multi-modal humor segment prediction in video</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2023-multi/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2023-multi/</guid><description/></item><item><title>Not only generative art: Stable diffusion for content-style disentanglement in art analysis</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2023-notonly/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2023-notonly/</guid><description/></item><item><title>Toward verifiable and reproducible human evaluation for text-to-image generation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2023-toward/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2023-toward/</guid><description/></item><item><title>Uncurated image-text datasets: Shedding light on demographic bias</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2023-uncurated/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2023-uncurated/</guid><description/></item><item><title>Real-time estimation of the remaining surgery duration for cataract surgery using deep convolutional neural networks and long short-term memory</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2023-realtime/</link><pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2023-realtime/</guid><description/></item><item><title>Improving facade parsing with vision transformers and line integration</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2024-facade/</link><pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2024-facade/</guid><description/></item><item><title>Explainability matters in medical applications</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/scaiosaka-2023/</link><pubDate>Wed, 01 Mar 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/scaiosaka-2023/</guid><description/></item><item><title>Development of a vertex finding algorithm using recurrent neural network</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/goto-2023-development/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/goto-2023-development/</guid><description/></item><item><title>Inference Time Evidences of Adversarial Attacks for Forensic on Transformers</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/lemarchant-2023-inference/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/lemarchant-2023-inference/</guid><description/></item><item><title>Toward better communication between humans and AI: What do neural networks see?</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/iitosaka-2023/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/iitosaka-2023/</guid><description/></item><item><title>Contrastive Losses Are Natural Criteria for Unsupervised Video Summarization</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2023-contrastive/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/pang-2023-contrastive/</guid><description/></item><item><title>Emotional Intensity Estimation based on Writer’s Personality</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/suzuki-2022-emotional/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/suzuki-2022-emotional/</guid><description/></item><item><title>Foundation of AI</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/isba-2022/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/isba-2022/</guid><description/></item><item><title>What do models see? Bias in neural networks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/sjtuou-2022/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/sjtuou-2022/</guid><description/></item><item><title>Deep Gesture Generation for Social Robots Using Type-Specific Libraries</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2022-deep/</link><pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2022-deep/</guid><description/></item><item><title>Corpus Construction for Historical Newspapers: A Case Study on Public Meeting Corpus Construction Using OCR Error Correction</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2022-corpus/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2022-corpus/</guid><description/></item><item><title>Depthwise spatio-temporal STFT convolutional neural networks for human action recognition</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kumawat-2021-stft/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kumawat-2021-stft/</guid><description/></item><item><title>深層学習の最近の話題と医療分野への応用</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/jos-2022/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/jos-2022/</guid><description/></item><item><title>分野を超えた人工知能研究と最新の話題について</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/isco-2022/</link><pubDate>Thu, 01 Sep 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/isco-2022/</guid><description/></item><item><title>Match them up: Visually explainable few-shot image classification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2022-match/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2022-match/</guid><description/></item><item><title>Multi-label disengagement and behavior prediction in online learning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2022-multi/</link><pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2022-multi/</guid><description/></item><item><title>A Japanese Dataset for Subjective and Objective Sentiment Polarity Classification in Micro Blog Domain</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/suzuki-2022-japanese/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/suzuki-2022-japanese/</guid><description/></item><item><title>AxIoU: An Axiomatically Justified Measure for Video Moment Retrieval</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/togashi-2022-cvpr/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/togashi-2022-cvpr/</guid><description/></item><item><title>Gender and racial bias in visual question answering datasets</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2022-facct/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2022-facct/</guid><description/></item><item><title>Optimal Correction Cost for Object Detection Evaluation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2022-cvpr/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2022-cvpr/</guid><description/></item><item><title>Quantifying Societal Bias Amplification in Image Captioning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2022-cvpr/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2022-cvpr/</guid><description/></item><item><title>Tone Classification for Political Advertising Video using Multimodal Cues</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/vo-2022-tone/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/vo-2022-tone/</guid><description/></item><item><title>Information Extraction from Public Meeting Articles</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/virgo-2022-sncs/</link><pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/virgo-2022-sncs/</guid><description/></item><item><title>Recent Machine Learning Techniques and Exploration of New Physics</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/plb-2022/</link><pubDate>Sun, 01 May 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/plb-2022/</guid><description/></item><item><title>Anonymous identity sampling and reusable synthesis for sensitive face camouflage</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kuang-2022-privacy/</link><pubDate>Tue, 01 Mar 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kuang-2022-privacy/</guid><description/></item><item><title>Integration of gesture generation system using gesture library with DIY robot design kit</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2022/</link><pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/teshima-2022/</guid><description/></item><item><title>The semantic typology of visually grounded paraphrases</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2021-semantic/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2021-semantic/</guid><description/></item><item><title>Explain me the painting: Multi-topic knowledgeable art description generation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/bai-2021-explain/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/bai-2021-explain/</guid><description/></item><item><title>GCNBoost: Artwork Classification by Label Propagation Through a Knowledge Graph</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/vaigh-202-gcnboost/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/vaigh-202-gcnboost/</guid><description/></item><item><title>Image Retrieval by Hierarchy-aware Deep Hashing Based on Multi-task Learning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-image/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-image/</guid><description/></item><item><title>SCOUTER: Slot attention-based classifier for explainable image recognition</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2021-scouter/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2021-scouter/</guid><description/></item><item><title>Transferring domain-agnostic knowledge in video question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2021-transferring/</link><pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wu-2021-transferring/</guid><description/></item><item><title>Built year prediction from Buddha face with heterogeneous labels</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/qian-2021-built/</link><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/qian-2021-built/</guid><description/></item><item><title>Visual question answering with textual representations for images</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2021-visual/</link><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hirota-2021-visual/</guid><description/></item><item><title>Learners' efficiency prediction using facial behavior analysis</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2021-learners/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2021-learners/</guid><description/></item><item><title>Museum Experience into a Souvenir: Generating Memorable Postcards from Guide Device Behavior Log</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/shoji-2021/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/shoji-2021/</guid><description/></item><item><title>PoseRN: A 2D pose refinement network for bias-free multi-view 3D human pose estimation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2021-posern/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2021-posern/</guid><description/></item><item><title>Attending self-attention: A case study of visually grounded supervision in vision-and-language transformers</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/samaran-2021-attending/</link><pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/samaran-2021-attending/</guid><description/></item><item><title>機械は世界をどう見ているのか？</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/asada-2021/</link><pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/asada-2021/</guid><description/></item><item><title>A comparative study of language Transformers for video question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2021-bert/</link><pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2021-bert/</guid><description/></item><item><title>MTUNet: Few-shot image classification with visual explanations</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-mtunet/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-mtunet/</guid><description/></item><item><title>WRIME: A new dataset for emotional intensity estimation with subjective and objective annotations</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kajiwara-2021-wrime/</link><pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kajiwara-2021-wrime/</guid><description/></item><item><title>Noisy-LSTM: Improving temporal awareness for video semantic segmentation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-noisy/</link><pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/wang-2021-noisy/</guid><description/></item><item><title>Generation and detection of media clones</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2021-generation/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2021-generation/</guid><description/></item><item><title>Preventing fake information generation against media clone attacks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2021-preventing/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2021-preventing/</guid><description/></item><item><title>The laughing machine: Predicting humor in video</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kayatani-2021-laughing/</link><pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kayatani-2021-laughing/</guid><description/></item><item><title>ContextNet: Representation and exploration for painting classification and retrieval in context</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-contextnet/</link><pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-contextnet/</guid><description/></item><item><title>Cross-lingual visual grounding</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/dong-2020-cross/</link><pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/dong-2020-cross/</guid><description/></item><item><title>IDSOU at WNUT-2020 Task 2: Identification of informative COVID-19 English tweets</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ohashi-2020-idsou/</link><pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ohashi-2020-idsou/</guid><description/></item><item><title>Improving topic modeling through homophily for legal documents</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ashihara-2020-improving/</link><pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ashihara-2020-improving/</guid><description/></item><item><title>Uncovering hidden challenges in query-based video moment retrieval</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2020-uncovering/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2020-uncovering/</guid><description/></item><item><title>Visually grounded paraphrase identification via gating and phrase localization</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2020-visually/</link><pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2020-visually/</guid><description/></item><item><title>A dataset and baselines for visual question answering on art</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-dataset/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-dataset/</guid><description/></item><item><title>Demographic Influences on Contemporary Art with Unsupervised Style Embeddings</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/huckle-2020/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/huckle-2020/</guid><description/></item><item><title>Knowledge-based video question answering with unsupervised scene descriptions</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-knowledgea/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-knowledgea/</guid><description/></item><item><title>Privacy sensitive large-margin model for face de-identification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/guo-2020-privacy/</link><pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/guo-2020-privacy/</guid><description/></item><item><title>Joint learning of vessel segmentation and artery/vein classification with post-processing</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2020-joint/</link><pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2020-joint/</guid><description/></item><item><title>Knowledge-Based Visual Question Answering in Videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-women/</link><pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2020-women/</guid><description/></item><item><title>Yoga-82: A new dataset for fine-grained classification of human poses</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2020-yoga/</link><pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2020-yoga/</guid><description/></item><item><title>Constructing a public meeting corpus</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2020-constructing/</link><pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2020-constructing/</guid><description/></item><item><title>Warmer environments increase implicit mental workload even if learning efficiency is enhanced</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kimura-2020-warmer/</link><pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kimura-2020-warmer/</guid><description/></item><item><title>BERT representations for video question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2020-bert/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2020-bert/</guid><description/></item><item><title>IterNet: Retinal image segmentation utilizing structural redundancy in vessel networks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2020-iternet/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/li-2020-iternet/</guid><description/></item><item><title>Toward predicting learners' efficiency for adaptive e-learning</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2020-toward/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2020-toward/</guid><description/></item><item><title>Video analytics in blended learning: Insights from learner-video interaction patterns</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/alizadeh-2020-video/</link><pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/alizadeh-2020-video/</guid><description/></item><item><title>KnowIT VQA: Answering knowledge-based questions about videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/gacria-2020-knowit/</link><pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/gacria-2020-knowit/</guid><description/></item><item><title>3D image reconstruction from multi-focus microscopic images</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yamaguchi-20203-d/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yamaguchi-20203-d/</guid><description/></item><item><title>Speech-driven face reenactment for a video sequence</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2020-speech/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2020-speech/</guid><description/></item><item><title>Public Meeting Corpus Construction and Content Delivery</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2019-public/</link><pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2019-public/</guid><description/></item><item><title>Human shape reconstruction with loose clothes from partially observed data by pose specific deformation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2019-human/</link><pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2019-human/</guid><description/></item><item><title>Legal information as a complex network: Improving topic modeling through homophily</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ashihara-2019-legal/</link><pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ashihara-2019-legal/</guid><description/></item><item><title>Adaptive gating mechanism for identifying visually grounded paraphrases</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-adaptive/</link><pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-adaptive/</guid><description/></item><item><title>BUDA.ART: A multimodal content-based analysis and retrieval system for Buddha statues</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/renoust-2019-budaart/</link><pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/renoust-2019-budaart/</guid><description/></item><item><title>Historical and modern features for Buddha statue classification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2019-historical/</link><pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2019-historical/</guid><description/></item><item><title>Using external knowledge in the deep learning framework</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-seminarkek/</link><pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-seminarkek/</guid><description/></item><item><title>Facial expression recognition with skip-connection to leverage low-level features</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2019-facial/</link><pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/verma-2019-facial/</guid><description/></item><item><title>Buddha statues archive retrieval system</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2019-miru/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2019-miru/</guid><description/></item><item><title>Collecting relation-aware video captions</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-miru/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-miru/</guid><description/></item><item><title>GANを用いた顔のRGB画像と奥行画像の同時生成</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kobayashi-2019/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kobayashi-2019/</guid><description/></item><item><title>Video meets knowledge in visual question answering</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-miru/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-miru/</guid><description/></item><item><title>Video question answering with BERT</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2019-miru/</link><pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yang-2019-miru/</guid><description/></item><item><title>AI/機械学習/深層学習入門</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/pyis-2019-seminaracc/</link><pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/pyis-2019-seminaracc/</guid><description/></item><item><title>Context-aware embeddings for automatic art analysis</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-context/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/garcia-2019-context/</guid><description/></item><item><title>Rethinking the evaluation of video summaries</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-rethinking/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2019-rethinking/</guid><description/></item><item><title>コメディドラマにおける字幕と表情を用いた笑い予測</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kayatani-2019/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kayatani-2019/</guid><description/></item><item><title>Multimodal learning analytics: Society 5.0 project in Japan</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/shirai-2019-multimodal/</link><pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/shirai-2019-multimodal/</guid><description/></item><item><title>Problems dealt with machine learning/deep learning and its applications to nuclear physics</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-nakano/</link><pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-nakano/</guid><description/></item><item><title>Talking Head Generation with Deep Phoneme and Viseme Representation and Generative Adversarial Networks</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yasui-2019-talking/</link><pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yasui-2019-talking/</guid><description/></item><item><title>情報学と物理学のクロスオーバー</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-cross/</link><pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/phys-2019-cross/</guid><description/></item><item><title>Faces in an Archive of Buddhism Pictures</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/renoust-2019-buddha/</link><pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/renoust-2019-buddha/</guid><description/></item><item><title>多重焦点顕微鏡画像列からの細胞の3次元形状復元</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/yamaguchi-2019/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/yamaguchi-2019/</guid><description/></item><item><title>Finding important people in a video using deep neural networks with conditional random fields</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-finding/</link><pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-finding/</guid><description/></item><item><title>Exploration and Mining of 50,000 Buddha Pictures</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2018-miru/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/ben-2018-miru/</guid><description/></item><item><title>iParaphrasing: Extracting visually grounded paraphrases via an image</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2018-ipara/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2018-ipara/</guid><description/></item><item><title>Iterative applications of image completion with CNN-based failure detection</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2018-iterative/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2018-iterative/</guid><description/></item><item><title>OpenCVとPythonによる機械学習プログラミング</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/michael-2018/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/michael-2018/</guid><description/></item><item><title>Phrase localization-based visually grounded paraphrase identification</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-miruphrase/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-miruphrase/</guid><description/></item><item><title>Representing a partially observed non-rigid 3D human using eigen-texture and eigen-deformation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kiura-2018-representing/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kiura-2018-representing/</guid><description/></item><item><title>Summarization of user-generated sports video by using deep action recognition features</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tejerodepablos-2018-summarization/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tejerodepablos-2018-summarization/</guid><description/></item><item><title>Synthesis of human shape in loose cloth using eigen-deformation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2019-miru/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/sayo-2019-miru/</guid><description/></item><item><title>Linking videos and languages: Representations and their applications</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-cvim/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-cvim/</guid><description/></item><item><title>Extracting Paraphrases Grounded by an Image</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2018-extracting/</link><pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/chu-2018-extracting/</guid><description/></item><item><title>Finding Video Parts with Natural Language</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-findinga/</link><pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2018-findinga/</guid><description/></item><item><title>自由視点画像生成のためのEigen-Texture法における係数の回帰</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2017-eigen/</link><pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2017-eigen/</guid><description/></item><item><title>Augmented reality marker hiding with texture deformation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kawai-2017-augmented/</link><pubDate>Sun, 01 Oct 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kawai-2017-augmented/</guid><description/></item><item><title>Video question answering to find a desired video segment</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2017-demo/</link><pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2017-demo/</guid><description/></item><item><title>Novel view synthesis with light-weight view-dependent texture mapping for a stereoscopic HMD</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/rongsirigul-2017-novel/</link><pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/rongsirigul-2017-novel/</guid><description/></item><item><title>画像処理・機械学習プログラミングOpenCV 3対応</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/opencv-2017/</link><pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/opencv-2017/</guid><description/></item><item><title>Video summarization using textual descriptions for authoring video blogs</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2017-video/</link><pubDate>Mon, 01 May 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2017-video/</guid><description/></item><item><title>DNNを用いたカメラの6自由度相対運動推定</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/hashioka-20178-dnn/</link><pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/hashioka-20178-dnn/</guid><description/></item><item><title>最近の重要な論文の紹介 -- テキストとの対応付けによる映像の理解に関連して</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/stair-2017/</link><pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/stair-2017/</guid><description/></item><item><title>Increasing pose comprehension through augmented reality reenactment</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2017-increasing/</link><pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2017-increasing/</guid><description/></item><item><title>ReMagicMirror: Action learning using human reenactment with the mirror metaphor</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2017-remagicmirroir/</link><pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2017-remagicmirroir/</guid><description/></item><item><title>Flexible human action recognition in depth video sequences using masked joint trajectories</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tejero-2016-flexible/</link><pubDate>Thu, 01 Dec 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tejero-2016-flexible/</guid><description/></item><item><title>深層学習を利用した映像要約への取り組み</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/stair-2016/</link><pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/stair-2016/</guid><description/></item><item><title>Video summarization using deep semantic features</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2016-video/</link><pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2016-video/</guid><description/></item><item><title>Learning joint representations of videos and sentences with web image search</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2016-learning/</link><pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2016-learning/</guid><description/></item><item><title>Human action recognition-based video summarization for RGB-D personal sports video</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tejerodepablo-2016-human/</link><pubDate>Fri, 01 Jul 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tejerodepablo-2016-human/</guid><description/></item><item><title>Joint representation of video and text using deep neural networks with help of web images</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/msra-2016/</link><pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/msra-2016/</guid><description/></item><item><title>Privacy protection for social video via background estimation and CRF-based videographer's intention modeling</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2016-privacy/</link><pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2016-privacy/</guid><description/></item><item><title>Novel View Synthesis Based on View-dependent Texture Mapping with Geometry-aware Color Continuity</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/katagiri-2016-novel/</link><pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/katagiri-2016-novel/</guid><description/></item><item><title>3D shape template generation from RGB-D images capturing a moving and deforming object</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-20163-d/</link><pubDate>Mon, 01 Feb 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-20163-d/</guid><description/></item><item><title>畳み込みニューラルネットワークを用いた修復失敗領域の自動検出による画像修復の反復的適用</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2016-dnn/</link><pubDate>Mon, 01 Feb 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2016-dnn/</guid><description/></item><item><title>Acceleration of View-dependent Texture Mapping-based Novel View Synthesis for stereoscopic HMD</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/rongsirigul-2016/</link><pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/rongsirigul-2016/</guid><description/></item><item><title>Evaluating protection capability for visual privacy information</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2016-evaluating/</link><pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2016-evaluating/</guid><description/></item><item><title>画像修復における畳み込みニューラルネットワークを用いた修復失敗領域の自動検出</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2015-ite/</link><pubDate>Tue, 01 Dec 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/tanaka-2015-ite/</guid><description/></item><item><title>2035年のマルチメディアの姿を予想--ICME 2015 会議レポート</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/icme-2015-report/</link><pubDate>Thu, 01 Oct 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/icme-2015-report/</guid><description/></item><item><title>OpenCV 3 プログラミングブック</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/opencv-2015/</link><pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/opencv-2015/</guid><description/></item><item><title>単一のRGB-Dカメラを用いた非剛体物体の3次元形状復元</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2015/</link><pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2015/</guid><description/></item><item><title>Facial expression preserving privacy protection using image melding</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2015-facial/</link><pubDate>Mon, 01 Jun 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2015-facial/</guid><description/></item><item><title>Textual description-based video summarization for video blogs</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2015-textual/</link><pubDate>Mon, 01 Jun 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2015-textual/</guid><description/></item><item><title>テクスチャの連続性を考慮した視点依存テクスチャマッピングによる自由視点画像生成</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/katagiri-2015/</link><pubDate>Sun, 01 Mar 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/katagiri-2015/</guid><description/></item><item><title>特徴点の明示的な対応付けを伴わないカメラ位置姿勢推定</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2015/</link><pubDate>Sun, 01 Mar 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2015/</guid><description/></item><item><title>AR image generation using view-dependent geometry modification and texture mapping</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2015-ar/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2015-ar/</guid><description/></item><item><title>Protection and utilization of privacy information via sensing</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2015-protection/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/babaguchi-2015-protection/</guid><description/></item><item><title>RGB-Dカメラを用いた非剛体物体の動き復元のためのRGB画像上の対応点に基づく3次元テンプレート生成</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2015-rgbd/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2015-rgbd/</guid><description/></item><item><title>テキストと映像の類似度を用いた映像要約</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2015-text/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/otani-2015-text/</guid><description/></item><item><title>特徴点の明示的な対応付けを伴わないカメラ位置姿勢推定</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2015-features/</link><pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2015-features/</guid><description/></item><item><title>RGB-Dカメラを用いた非剛体物体の動き復元のための3次元テンプレート形状生成</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2014-rgb/</link><pubDate>Mon, 01 Dec 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2014-rgb/</guid><description/></item><item><title>特徴点の類似度尺度による対応付けを伴わないカメラ位置姿勢推定手法の検討</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2014-ite/</link><pubDate>Mon, 01 Sep 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kurokawa-2014-ite/</guid><description/></item><item><title>Background estimation for a single omnidirectional image sequence captured with a moving camera</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kawai-2014-background/</link><pubDate>Tue, 01 Jul 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kawai-2014-background/</guid><description/></item><item><title>Free-viewpoint AR human-motion reenactment based on a single RGB-D video stream</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2014-free/</link><pubDate>Tue, 01 Jul 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/dayrit-2014-free/</guid><description/></item><item><title>画像のコンテキストを保持した視覚的に自然なプライバシー保護処理</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2014/</link><pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2014/</guid><description/></item><item><title>自由視点画像生成に基づく移動撮影した全方位動画像からの動物体除去</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/inoue-2014/</link><pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/inoue-2014/</guid><description/></item><item><title>Single RGB-D Video-stream Based Human-motion Reenactment</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/enzo-2014-single/</link><pubDate>Sat, 01 Feb 2014 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/enzo-2014-single/</guid><description/></item><item><title>Augmented reality image generation with virtualized real objects using view-dependent texture and geometry</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2013-augmented/</link><pubDate>Tue, 01 Oct 2013 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2013-augmented/</guid><description/></item><item><title>Inferring what the videographer wanted to capture</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2013-inferring/</link><pubDate>Sun, 01 Sep 2013 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2013-inferring/</guid><description/></item><item><title>Real-time privacy protection system for social videos using intentionally-captured persons detection</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2013-realtime/</link><pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2013-realtime/</guid><description/></item><item><title>拡張現実感のための視点依存テクスチャ・ジオメトリに基づく仮想化実物体の輪郭形状の修復</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uno-2013-ar/</link><pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uno-2013-ar/</guid><description/></item><item><title>Markov random field-based real-time detection of intentionally-captured persons</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2012-markov/</link><pubDate>Sat, 01 Sep 2012 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/koyama-2012-markov/</guid><description/></item><item><title>顔画像に対するプライバシー保護処理の有効性の定量的評価</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2012-privacy/</link><pubDate>Sun, 01 Jul 2012 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2012-privacy/</guid><description/></item><item><title>Intended human object detection for automatically protecting privacy in mobile video surveillance</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2012-intended/</link><pubDate>Thu, 01 Mar 2012 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2012-intended/</guid><description/></item><item><title>Extracting intentionally captured regions using point trajectories</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-extracting/</link><pubDate>Tue, 01 Nov 2011 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-extracting/</guid><description/></item><item><title>Indoor positioning system using digital audio watermarking</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-indoor/</link><pubDate>Tue, 01 Nov 2011 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-indoor/</guid><description/></item><item><title>Automatic generation of privacy-protected videos using background estimation</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-automatic/</link><pubDate>Fri, 01 Jul 2011 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2011-automatic/</guid><description/></item><item><title>カメラの動きと映像特徴からの撮影者が意図した領域の推定</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2011/</link><pubDate>Fri, 01 Jul 2011 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2011/</guid><description/></item><item><title>Automatically protecting privacy in consumer generated videos using intended human object detector</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2010-automatically/</link><pubDate>Fri, 01 Oct 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2010-automatically/</guid><description/></item><item><title>Discriminating intended human objects in consumer videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2010-discriminating/</link><pubDate>Sun, 01 Aug 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2010-discriminating/</guid><description/></item><item><title>Real-time user position estimation in indoor environments using digital watermarking for audio signals</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2010-realtime/</link><pubDate>Sun, 01 Aug 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2010-realtime/</guid><description/></item><item><title>Detecting intended human objects in human-captured videos</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2010-detecting/</link><pubDate>Tue, 01 Jun 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2010-detecting/</guid><description/></item><item><title>Digital diorama: Sensing-based real-world visualization</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2010-digital/</link><pubDate>Tue, 01 Jun 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/takehara-2010-digital/</guid><description/></item><item><title>映像中の撮影者が意図した人物被写体の検出</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2010/</link><pubDate>Mon, 01 Mar 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2010/</guid><description/></item><item><title>音響電子透かしを用いた屋内での録音位置推定</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2010/</link><pubDate>Mon, 01 Mar 2010 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2010/</guid><description/></item><item><title>映像特徴に基づく撮影者が意図した人物被写体の推定</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2009/</link><pubDate>Sat, 01 Aug 2009 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/uegaki-2009/</guid><description/></item><item><title>Watermarked movie soundtrack finds the position of the camcorder in a theater</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2009-watermarked/</link><pubDate>Sun, 01 Mar 2009 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2009-watermarked/</guid><description/></item><item><title>音響電子透かしの検出強度を用いた位置推定</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2009/</link><pubDate>Sun, 01 Mar 2009 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/kaneto-2009/</guid><description/></item><item><title>Maximum-likelihood estimation of recording position based on audio watermarking</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2007-maximum/</link><pubDate>Thu, 01 Nov 2007 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2007-maximum/</guid><description/></item><item><title>Determining Recording Location Based on Synchronization Positions of Audio watermarking</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2007-determining/</link><pubDate>Sun, 01 Apr 2007 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2007-determining/</guid><description/></item><item><title>Estimation of recording location using audio watermarking</title><link>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2006-estimation/</link><pubDate>Fri, 01 Sep 2006 00:00:00 +0000</pubDate><guid>https://im.sanken.osaka-u.ac.jp/ja/publication/nakashima-2006-estimation/</guid><description/></item></channel></rss>